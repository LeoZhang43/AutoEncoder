[
  {
    "arxiv_id": "9905014v1",
    "title": "Hierarchical Reinforcement Learning with the MAXQ Value Function\n  Decomposition",
    "authors": [
      "Thomas G. Dietterich"
    ],
    "abstract": "This paper presents the MAXQ approach to hierarchical reinforcement learning\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\nof smaller MDPs and decomposing the value function of the target MDP into an\nadditive combination of the value functions of the smaller MDPs. The paper\ndefines the MAXQ hierarchy, proves formal results on its representational\npower, and establishes five conditions for the safe use of state abstractions.\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\nthat it converges wih probability 1 to a kind of locally-optimal policy known\nas a recursively optimal policy, even in the presence of the five kinds of\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\nthrough a series of experiments in three domains and shows experimentally that\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\nvalue function has an important benefit: it makes it possible to compute and\nexecute an improved, non-hierarchical policy via a procedure similar to the\npolicy improvement step of policy iteration. The paper demonstrates the\neffectiveness of this non-hierarchical execution experimentally. Finally, the\npaper concludes with a comparison to related work and a discussion of the\ndesign tradeoffs in hierarchical reinforcement learning.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "1999-05-21T14:26:07Z",
    "updated": "1999-05-21T14:26:07Z",
    "abstract_stats": {
      "total_words": 223,
      "unique_words": 111,
      "total_sentences": 7,
      "avg_words_per_sentence": 31.857142857142858,
      "avg_word_length": 5.367713004484305
    }
  },
  {
    "arxiv_id": "9905015v1",
    "title": "State Abstraction in MAXQ Hierarchical Reinforcement Learning",
    "authors": [
      "Thomas G. Dietterich"
    ],
    "abstract": "Many researchers have explored methods for hierarchical reinforcement\nlearning (RL) with temporal abstractions, in which abstract actions are defined\nthat can perform many primitive actions before terminating. However, little is\nknown about learning with state abstractions, in which aspects of the state\nspace are ignored. In previous work, we developed the MAXQ method for\nhierarchical RL. In this paper, we define five conditions under which state\nabstraction can be combined with the MAXQ value function decomposition. We\nprove that the MAXQ-Q learning algorithm converges under these conditions and\nshow experimentally that state abstraction is important for the successful\napplication of MAXQ-Q learning.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "1999-05-21T14:49:39Z",
    "updated": "1999-05-21T14:49:39Z",
    "abstract_stats": {
      "total_words": 104,
      "unique_words": 65,
      "total_sentences": 5,
      "avg_words_per_sentence": 20.8,
      "avg_word_length": 5.721153846153846
    }
  },
  {
    "arxiv_id": "0001004v1",
    "title": "Multiplicative Algorithm for Orthgonal Groups and Independent Component\n  Analysis",
    "authors": [
      "Toshinao Akuzawa"
    ],
    "abstract": "The multiplicative Newton-like method developed by the author et al. is\nextended to the situation where the dynamics is restricted to the orthogonal\ngroup. A general framework is constructed without specifying the cost function.\nThough the restriction to the orthogonal groups makes the problem somewhat\ncomplicated, an explicit expression for the amount of individual jumps is\nobtained. This algorithm is exactly second-order-convergent. The global\ninstability inherent in the Newton method is remedied by a\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\napplied to the independent component analysis. Its remarkable performance is\nillustrated by a numerical simulation.",
    "categories": [
      "cs.LG",
      "G.1.6"
    ],
    "published": "2000-01-07T06:20:53Z",
    "updated": "2000-01-07T06:20:53Z",
    "abstract_stats": {
      "total_words": 103,
      "unique_words": 72,
      "total_sentences": 8,
      "avg_words_per_sentence": 12.875,
      "avg_word_length": 5.747572815533981
    }
  },
  {
    "arxiv_id": "0002006v1",
    "title": "Multiplicative Nonholonomic/Newton -like Algorithm",
    "authors": [
      "Toshinao Akuzawa",
      "Noboru Murata"
    ],
    "abstract": "We construct new algorithms from scratch, which use the fourth order cumulant\nof stochastic variables for the cost function. The multiplicative updating rule\nhere constructed is natural from the homogeneous nature of the Lie group and\nhas numerous merits for the rigorous treatment of the dynamics. As one\nconsequence, the second order convergence is shown. For the cost function,\nfunctions invariant under the componentwise scaling are choosen. By identifying\npoints which can be transformed to each other by the scaling, we assume that\nthe dynamics is in a coset space. In our method, a point can move toward any\ndirection in this coset. Thus, no prewhitening is required.",
    "categories": [
      "cs.LG",
      "G.1.6"
    ],
    "published": "2000-02-09T06:44:28Z",
    "updated": "2000-02-09T06:44:28Z",
    "abstract_stats": {
      "total_words": 108,
      "unique_words": 76,
      "total_sentences": 7,
      "avg_words_per_sentence": 15.428571428571429,
      "avg_word_length": 5.12962962962963
    }
  },
  {
    "arxiv_id": "0009001v3",
    "title": "Complexity analysis for algorithmically simple strings",
    "authors": [
      "Andrei N. Soklakov"
    ],
    "abstract": "Given a reference computer, Kolmogorov complexity is a well defined function\non all binary strings. In the standard approach, however, only the asymptotic\nproperties of such functions are considered because they do not depend on the\nreference computer. We argue that this approach can be more useful if it is\nrefined to include an important practical case of simple binary strings.\nKolmogorov complexity calculus may be developed for this case if we restrict\nthe class of available reference computers. The interesting problem is to\ndefine a class of computers which is restricted in a {\\it natural} way modeling\nthe real-life situation where only a limited class of computers is physically\navailable to us. We give an example of what such a natural restriction might\nlook like mathematically, and show that under such restrictions some error\nterms, even logarithmic in complexity, can disappear from the standard\ncomplexity calculus.\n  Keywords: Kolmogorov complexity; Algorithmic information theory.",
    "categories": [
      "cs.LG",
      "E.4; F.2; I.2"
    ],
    "published": "2000-09-05T18:54:58Z",
    "updated": "2002-02-26T01:51:09Z",
    "abstract_stats": {
      "total_words": 154,
      "unique_words": 96,
      "total_sentences": 7,
      "avg_words_per_sentence": 22.0,
      "avg_word_length": 5.376623376623376
    }
  },
  {
    "arxiv_id": "0009007v1",
    "title": "Robust Classification for Imprecise Environments",
    "authors": [
      "Foster Provost",
      "Tom Fawcett"
    ],
    "abstract": "In real-world environments it usually is difficult to specify target\noperating conditions precisely, for example, target misclassification costs.\nThis uncertainty makes building robust classification systems problematic. We\nshow that it is possible to build a hybrid classifier that will perform at\nleast as well as the best available classifier for any target conditions. In\nsome cases, the performance of the hybrid actually can surpass that of the best\nknown classifier. This robust performance extends across a wide variety of\ncomparison frameworks, including the optimization of metrics such as accuracy,\nexpected cost, lift, precision, recall, and workforce utilization. The hybrid\nalso is efficient to build, to store, and to update. The hybrid is based on a\nmethod for the comparison of classifier performance that is robust to imprecise\nclass distributions and misclassification costs. The ROC convex hull (ROCCH)\nmethod combines techniques from ROC analysis, decision analysis and\ncomputational geometry, and adapts them to the particulars of analyzing learned\nclassifiers. The method is efficient and incremental, minimizes the management\nof classifier performance data, and allows for clear visual comparisons and\nsensitivity analyses. Finally, we point to empirical evidence that a robust\nhybrid classifier indeed is needed for many real-world problems.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2000-09-13T21:09:47Z",
    "updated": "2000-09-13T21:09:47Z",
    "abstract_stats": {
      "total_words": 200,
      "unique_words": 116,
      "total_sentences": 10,
      "avg_words_per_sentence": 20.0,
      "avg_word_length": 5.695
    }
  },
  {
    "arxiv_id": "0011032v1",
    "title": "Top-down induction of clustering trees",
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Jan Ramon"
    ],
    "abstract": "An approach to clustering is presented that adapts the basic top-down\ninduction of decision trees method towards clustering. To this aim, it employs\nthe principles of instance based learning. The resulting methodology is\nimplemented in the TIC (Top down Induction of Clustering trees) system for\nfirst order clustering. The TIC system employs the first order logical decision\ntree representation of the inductive logic programming system Tilde. Various\nexperiments with TIC are presented, in both propositional and relational\ndomains.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2000-11-21T21:51:01Z",
    "updated": "2000-11-21T21:51:01Z",
    "abstract_stats": {
      "total_words": 79,
      "unique_words": 51,
      "total_sentences": 5,
      "avg_words_per_sentence": 15.8,
      "avg_word_length": 5.658227848101266
    }
  },
  {
    "arxiv_id": "0011044v1",
    "title": "Scaling Up Inductive Logic Programming by Learning from Interpretations",
    "authors": [
      "Hendrik Blockeel",
      "Luc De Raedt",
      "Nico Jacobs",
      "Bart Demoen"
    ],
    "abstract": "When comparing inductive logic programming (ILP) and attribute-value learning\ntechniques, there is a trade-off between expressive power and efficiency.\nInductive logic programming techniques are typically more expressive but also\nless efficient. Therefore, the data sets handled by current inductive logic\nprogramming systems are small according to general standards within the data\nmining community. The main source of inefficiency lies in the assumption that\nseveral examples may be related to each other, so they cannot be handled\nindependently.\n  Within the learning from interpretations framework for inductive logic\nprogramming this assumption is unnecessary, which allows to scale up existing\nILP algorithms. In this paper we explain this learning setting in the context\nof relational databases. We relate the setting to propositional data mining and\nto the classical ILP setting, and show that learning from interpretations\ncorresponds to learning from multiple relations and thus extends the\nexpressiveness of propositional learning, while maintaining its efficiency to a\nlarge extent (which is not the case in the classical ILP setting).\n  As a case study, we present two alternative implementations of the ILP system\nTilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which\nloads all data in main memory, and Tilde-LDS, which loads the examples one by\none. We experimentally compare the implementations, showing Tilde-LDS can\nhandle large data sets (in the order of 100,000 examples or 100 MB) and indeed\nscales up linearly in the number of examples.",
    "categories": [
      "cs.LG",
      "I.2.6 ; I.2.3"
    ],
    "published": "2000-11-29T12:14:50Z",
    "updated": "2000-11-29T12:14:50Z",
    "abstract_stats": {
      "total_words": 240,
      "unique_words": 132,
      "total_sentences": 9,
      "avg_words_per_sentence": 26.666666666666668,
      "avg_word_length": 5.445833333333334
    }
  },
  {
    "arxiv_id": "0103003v1",
    "title": "Learning Policies with External Memory",
    "authors": [
      "Leonid Peshkin",
      "Nicolas Meuleau",
      "Leslie Kaelbling"
    ],
    "abstract": "In order for an agent to perform well in partially observable domains, it is\nusually necessary for actions to depend on the history of observations. In this\npaper, we explore a {\\it stigmergic} approach, in which the agent's actions\ninclude the ability to set and clear bits in an external memory, and the\nexternal memory is included as part of the input to the agent. In this case, we\nneed to learn a reactive policy in a highly non-Markovian domain. We explore\ntwo algorithms: SARSA(\\lambda), which has had empirical success in partially\nobservable domains, and VAPS, a new algorithm due to Baird and Moore, with\nconvergence guarantees in partially observable domains. We compare the\nperformance of these two algorithms on benchmark problems.",
    "categories": [
      "cs.LG",
      "I.2.8;I.2.6;I.2.11;I.2;I.2.3"
    ],
    "published": "2001-03-02T01:55:46Z",
    "updated": "2001-03-02T01:55:46Z",
    "abstract_stats": {
      "total_words": 125,
      "unique_words": 74,
      "total_sentences": 5,
      "avg_words_per_sentence": 25.0,
      "avg_word_length": 4.8
    }
  },
  {
    "arxiv_id": "0110036v1",
    "title": "Efficient algorithms for decision tree cross-validation",
    "authors": [
      "Hendrik Blockeel",
      "Jan Struyf"
    ],
    "abstract": "Cross-validation is a useful and generally applicable technique often\nemployed in machine learning, including decision tree induction. An important\ndisadvantage of straightforward implementation of the technique is its\ncomputational overhead. In this paper we show that, for decision trees, the\ncomputational overhead of cross-validation can be reduced significantly by\nintegrating the cross-validation with the normal decision tree induction\nprocess. We discuss how existing decision tree algorithms can be adapted to\nthis aim, and provide an analysis of the speedups these adaptations may yield.\nThe analysis is supported by experimental results.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2001-10-17T15:45:23Z",
    "updated": "2001-10-17T15:45:23Z",
    "abstract_stats": {
      "total_words": 93,
      "unique_words": 61,
      "total_sentences": 5,
      "avg_words_per_sentence": 18.6,
      "avg_word_length": 5.881720430107527
    }
  },
  {
    "arxiv_id": "0211003v1",
    "title": "Evaluation of the Performance of the Markov Blanket Bayesian Classifier\n  Algorithm",
    "authors": [
      "Michael G. Madden"
    ],
    "abstract": "The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for\nconstruction of probabilistic classifiers. This paper presents an empirical\ncomparison of the MBBC algorithm with three other Bayesian classifiers: Naive\nBayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these\nare implemented using the K2 framework of Cooper and Herskovits. The\nclassifiers are compared in terms of their performance (using simple accuracy\nmeasures and ROC curves) and speed, on a range of standard benchmark data sets.\nIt is concluded that MBBC is competitive in terms of speed and accuracy with\nthe other algorithms considered.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2002-11-01T18:09:56Z",
    "updated": "2002-11-01T18:09:56Z",
    "abstract_stats": {
      "total_words": 98,
      "unique_words": 64,
      "total_sentences": 5,
      "avg_words_per_sentence": 19.6,
      "avg_word_length": 5.489795918367347
    }
  },
  {
    "arxiv_id": "0211007v1",
    "title": "Approximating Incomplete Kernel Matrices by the em Algorithm",
    "authors": [
      "Koji Tsuda",
      "Shotaro Akaho",
      "Kiyoshi Asai"
    ],
    "abstract": "In biological data, it is often the case that observed data are available\nonly for a subset of samples. When a kernel matrix is derived from such data,\nwe have to leave the entries for unavailable samples as missing. In this paper,\nwe make use of a parametric model of kernel matrices, and estimate missing\nentries by fitting the model to existing entries. The parametric model is\ncreated as a set of spectral variants of a complete kernel matrix derived from\nanother information source. For model fitting, we adopt the em algorithm based\non the information geometry of positive definite matrices. We will report\npromising results on bacteria clustering experiments using two marker\nsequences: 16S and gyrB.",
    "categories": [
      "cs.LG",
      "I2.6; I5.2"
    ],
    "published": "2002-11-07T07:21:58Z",
    "updated": "2002-11-07T07:21:58Z",
    "abstract_stats": {
      "total_words": 117,
      "unique_words": 73,
      "total_sentences": 6,
      "avg_words_per_sentence": 19.5,
      "avg_word_length": 4.948717948717949
    }
  },
  {
    "arxiv_id": "0309015v1",
    "title": "Reliable and Efficient Inference of Bayesian Networks from Sparse Data\n  by Statistical Learning Theory",
    "authors": [
      "Dominik Janzing",
      "Daniel Herrmann"
    ],
    "abstract": "To learn (statistical) dependencies among random variables requires\nexponentially large sample size in the number of observed random variables if\nany arbitrary joint probability distribution can occur.\n  We consider the case that sparse data strongly suggest that the probabilities\ncan be described by a simple Bayesian network, i.e., by a graph with small\nin-degree \\Delta. Then this simple law will also explain further data with high\nconfidence. This is shown by calculating bounds on the VC dimension of the set\nof those probability measures that correspond to simple graphs. This allows to\nselect networks by structural risk minimization and gives reliability bounds on\nthe error of the estimated joint measure without (in contrast to a previous\npaper) any prior assumptions on the set of possible joint measures.\n  The complexity for searching the optimal Bayesian networks of in-degree\n\\Delta increases only polynomially in the number of random varibales for\nconstant \\Delta and the optimal joint measure associated with a given graph can\nbe found by convex optimization.",
    "categories": [
      "cs.LG",
      "K.3.2"
    ],
    "published": "2003-09-10T13:56:41Z",
    "updated": "2003-09-10T13:56:41Z",
    "abstract_stats": {
      "total_words": 169,
      "unique_words": 102,
      "total_sentences": 8,
      "avg_words_per_sentence": 21.125,
      "avg_word_length": 5.266272189349112
    }
  },
  {
    "arxiv_id": "0311042v1",
    "title": "Toward Attribute Efficient Learning Algorithms",
    "authors": [
      "Adam R. Klivans",
      "Rocco A. Servedio"
    ],
    "abstract": "We make progress on two important problems regarding attribute efficient\nlearnability.\n  First, we give an algorithm for learning decision lists of length $k$ over\n$n$ variables using $2^{\\tilde{O}(k^{1/3})} \\log n$ examples and time\n$n^{\\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision\nlists that has both subexponential sample complexity and subexponential running\ntime in the relevant parameters. Our approach establishes a relationship\nbetween attribute efficient learning and polynomial threshold functions and is\nbased on a new construction of low degree, low weight polynomial threshold\nfunctions for decision lists. For a wide range of parameters our construction\nmatches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives\nan essentially optimal tradeoff between polynomial threshold function degree\nand weight.\n  Second, we give an algorithm for learning an unknown parity function on $k$\nout of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$.\nFor $k=o(\\log n)$ this yields a polynomial time algorithm with sample\ncomplexity $o(n)$. This is the first polynomial time algorithm for learning\nparity on a superconstant number of variables with sublinear sample complexity.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2003-11-27T05:34:04Z",
    "updated": "2003-11-27T05:34:04Z",
    "abstract_stats": {
      "total_words": 196,
      "unique_words": 88,
      "total_sentences": 8,
      "avg_words_per_sentence": 24.5,
      "avg_word_length": 5.066326530612245
    }
  },
  {
    "arxiv_id": "0312004v1",
    "title": "Improving spam filtering by combining Naive Bayes with simple k-nearest\n  neighbor searches",
    "authors": [
      "Daniel Etzold"
    ],
    "abstract": "Using naive Bayes for email classification has become very popular within the\nlast few months. They are quite easy to implement and very efficient. In this\npaper we want to present empirical results of email classification using a\ncombination of naive Bayes and k-nearest neighbor searches. Using this\ntechnique we show that the accuracy of a Bayes filter can be improved slightly\nfor a high number of features and significantly for a small number of features.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2003-11-30T20:41:18Z",
    "updated": "2003-11-30T20:41:18Z",
    "abstract_stats": {
      "total_words": 77,
      "unique_words": 52,
      "total_sentences": 4,
      "avg_words_per_sentence": 19.25,
      "avg_word_length": 4.935064935064935
    }
  },
  {
    "arxiv_id": "0401005v1",
    "title": "About Unitary Rating Score Constructing",
    "authors": [
      "Kromer Victor"
    ],
    "abstract": "It is offered to pool test points of different subjects and different aspects\nof the same subject together in order to get the unitary rating score, by the\nway of nonlinear transformation of indicator points in accordance with Zipf's\ndistribution. It is proposed to use the well-studied distribution of\nIntellectuality Quotient IQ as the reference distribution for latent variable\n\"progress in studies\".",
    "categories": [
      "cs.LG",
      "1.2.6"
    ],
    "published": "2004-01-08T07:50:51Z",
    "updated": "2004-01-08T07:50:51Z",
    "abstract_stats": {
      "total_words": 64,
      "unique_words": 46,
      "total_sentences": 2,
      "avg_words_per_sentence": 32.0,
      "avg_word_length": 5.234375
    }
  },
  {
    "arxiv_id": "0412003v1",
    "title": "Mining Heterogeneous Multivariate Time-Series for Learning Meaningful\n  Patterns: Application to Home Health Telecare",
    "authors": [
      "Florence Duchene",
      "Catherine Garbay",
      "Vincent Rialle"
    ],
    "abstract": "For the last years, time-series mining has become a challenging issue for\nresearchers. An important application lies in most monitoring purposes, which\nrequire analyzing large sets of time-series for learning usual patterns. Any\ndeviation from this learned profile is then considered as an unexpected\nsituation. Moreover, complex applications may involve the temporal study of\nseveral heterogeneous parameters. In that paper, we propose a method for mining\nheterogeneous multivariate time-series for learning meaningful patterns. The\nproposed approach allows for mixed time-series -- containing both pattern and\nnon-pattern data -- such as for imprecise matches, outliers, stretching and\nglobal translating of patterns instances in time. We present the early results\nof our approach in the context of monitoring the health status of a person at\nhome. The purpose is to build a behavioral profile of a person by analyzing the\ntime variations of several quantitative or qualitative parameters recorded\nthrough a provision of sensors installed in the home.",
    "categories": [
      "cs.LG",
      "G.3"
    ],
    "published": "2004-12-01T16:32:49Z",
    "updated": "2004-12-01T16:32:49Z",
    "abstract_stats": {
      "total_words": 159,
      "unique_words": 101,
      "total_sentences": 8,
      "avg_words_per_sentence": 19.875,
      "avg_word_length": 5.50314465408805
    }
  },
  {
    "arxiv_id": "0502016v1",
    "title": "Stability Analysis for Regularized Least Squares Regression",
    "authors": [
      "Cynthia Rudin"
    ],
    "abstract": "We discuss stability for a class of learning algorithms with respect to noisy\nlabels. The algorithms we consider are for regression, and they involve the\nminimization of regularized risk functionals, such as L(f) := 1/N sum_i\n(f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when\ny_i is a noisy version of f*(x_i) for some function f* in H, the output of the\nalgorithm converges to f* as the regularization term and noise simultaneously\nvanish. We consider two flavors of this problem, one where a data set of N\npoints remains fixed, and the other where N -> infinity. For the case where N\n-> infinity, we give conditions for convergence to f_E (the function which is\nthe expectation of y(x) for each x), as lambda -> 0. For the fixed N case, we\ndescribe the limiting 'non-noisy', 'non-regularized' function f*, and give\nconditions for convergence. In the process, we develop a set of tools for\ndealing with functionals such as L(f), which are applicable to many other\nproblems in learning theory.",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-02-03T19:54:02Z",
    "updated": "2005-02-03T19:54:02Z",
    "abstract_stats": {
      "total_words": 181,
      "unique_words": 91,
      "total_sentences": 7,
      "avg_words_per_sentence": 25.857142857142858,
      "avg_word_length": 4.3535911602209945
    }
  },
  {
    "arxiv_id": "0504001v1",
    "title": "Probabilistic and Team PFIN-type Learning: General Properties",
    "authors": [
      "Andris Ambainis"
    ],
    "abstract": "We consider the probability hierarchy for Popperian FINite learning and study\nthe general properties of this hierarchy. We prove that the probability\nhierarchy is decidable, i.e. there exists an algorithm that receives p_1 and\np_2 and answers whether PFIN-type learning with the probability of success p_1\nis equivalent to PFIN-type learning with the probability of success p_2.\n  To prove our result, we analyze the topological structure of the probability\nhierarchy. We prove that it is well-ordered in descending ordering and\norder-equivalent to ordinal epsilon_0. This shows that the structure of the\nhierarchy is very complicated.\n  Using similar methods, we also prove that, for PFIN-type learning, team\nlearning and probabilistic learning are of the same power.",
    "categories": [
      "cs.LG",
      "F.1.1, I.2.6"
    ],
    "published": "2005-03-31T23:04:28Z",
    "updated": "2005-03-31T23:04:28Z",
    "abstract_stats": {
      "total_words": 121,
      "unique_words": 62,
      "total_sentences": 8,
      "avg_words_per_sentence": 15.125,
      "avg_word_length": 5.223140495867769
    }
  },
  {
    "arxiv_id": "0506004v4",
    "title": "Non-asymptotic calibration and resolution",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "We analyze a new algorithm for probability forecasting of binary observations\non the basis of the available data, without making any assumptions about the\nway the observations are generated. The algorithm is shown to be well\ncalibrated and to have good resolution for long enough sequences of\nobservations and for a suitable choice of its parameter, a kernel on the\nCartesian product of the forecast space $[0,1]$ and the data space. Our main\nresults are non-asymptotic: we establish explicit inequalities, shown to be\ntight, for the performance of the algorithm.",
    "categories": [
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "published": "2005-06-01T14:03:20Z",
    "updated": "2006-07-01T13:46:30Z",
    "abstract_stats": {
      "total_words": 92,
      "unique_words": 58,
      "total_sentences": 3,
      "avg_words_per_sentence": 30.666666666666668,
      "avg_word_length": 5.0
    }
  },
  {
    "arxiv_id": "0506007v2",
    "title": "Defensive forecasting for linear protocols",
    "authors": [
      "Vladimir Vovk",
      "Ilia Nouretdinov",
      "Akimichi Takemura",
      "Glenn Shafer"
    ],
    "abstract": "We consider a general class of forecasting protocols, called \"linear\nprotocols\", and discuss several important special cases, including multi-class\nforecasting. Forecasting is formalized as a game between three players:\nReality, whose role is to generate observations; Forecaster, whose goal is to\npredict the observations; and Skeptic, who tries to make money on any lack of\nagreement between Forecaster's predictions and the actual observations. Our\nmain mathematical result is that for any continuous strategy for Skeptic in a\nlinear protocol there exists a strategy for Forecaster that does not allow\nSkeptic's capital to grow. This result is a meta-theorem that allows one to\ntransform any continuous law of probability in a linear protocol into a\nforecasting strategy whose predictions are guaranteed to satisfy this law. We\napply this meta-theorem to a weak law of large numbers in Hilbert spaces to\nobtain a version of the K29 prediction algorithm for linear protocols and show\nthat this version also satisfies the attractive properties of proper\ncalibration and resolution under a suitable choice of its kernel parameter,\nwith no assumptions about the way the data is generated.",
    "categories": [
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "published": "2005-06-02T13:26:43Z",
    "updated": "2005-09-24T16:55:14Z",
    "abstract_stats": {
      "total_words": 188,
      "unique_words": 108,
      "total_sentences": 5,
      "avg_words_per_sentence": 37.6,
      "avg_word_length": 5.2287234042553195
    }
  },
  {
    "arxiv_id": "0506057v2",
    "title": "About one 3-parameter Model of Testing",
    "authors": [
      "Kromer Victor"
    ],
    "abstract": "This article offers a 3-parameter model of testing, with 1) the difference\nbetween the ability level of the examinee and item difficulty; 2) the examinee\ndiscrimination and 3) the item discrimination as model parameters.",
    "categories": [
      "cs.LG",
      "I.2.6; K.3.2"
    ],
    "published": "2005-06-14T04:00:38Z",
    "updated": "2005-07-21T02:43:12Z",
    "abstract_stats": {
      "total_words": 35,
      "unique_words": 24,
      "total_sentences": 1,
      "avg_words_per_sentence": 35.0,
      "avg_word_length": 5.142857142857143
    }
  },
  {
    "arxiv_id": "0506085v1",
    "title": "On the Job Training",
    "authors": [
      "Jason E. Holt"
    ],
    "abstract": "We propose a new framework for building and evaluating machine learning\nalgorithms. We argue that many real-world problems require an agent which must\nquickly learn to respond to demands, yet can continue to perform and respond to\nnew training throughout its useful life. We give a framework for how such\nagents can be built, describe several metrics for evaluating them, and show\nthat subtle changes in system construction can significantly affect agent\nperformance.",
    "categories": [
      "cs.LG",
      "K.3.2"
    ],
    "published": "2005-06-22T21:21:13Z",
    "updated": "2005-06-22T21:21:13Z",
    "abstract_stats": {
      "total_words": 74,
      "unique_words": 56,
      "total_sentences": 3,
      "avg_words_per_sentence": 24.666666666666668,
      "avg_word_length": 5.243243243243243
    }
  },
  {
    "arxiv_id": "0507033v2",
    "title": "Multiresolution Kernels",
    "authors": [
      "Marco Cuturi",
      "Kenji Fukumizu"
    ],
    "abstract": "We present in this work a new methodology to design kernels on data which is\nstructured with smaller components, such as text, images or sequences. This\nmethodology is a template procedure which can be applied on most kernels on\nmeasures and takes advantage of a more detailed \"bag of components\"\nrepresentation of the objects. To obtain such a detailed description, we\nconsider possible decompositions of the original bag into a collection of\nnested bags, following a prior knowledge on the objects' structure. We then\nconsider these smaller bags to compare two objects both in a detailed\nperspective, stressing local matches between the smaller bags, and in a global\nor coarse perspective, by considering the entire bag. This multiresolution\napproach is likely to be best suited for tasks where the coarse approach is not\nprecise enough, and where a more subtle mixture of both local and global\nsimilarities is necessary to compare objects. The approach presented here would\nnot be computationally tractable without a factorization trick that we\nintroduce before presenting promising results on an image retrieval task.",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-07-13T05:45:28Z",
    "updated": "2005-11-14T08:18:49Z",
    "abstract_stats": {
      "total_words": 177,
      "unique_words": 104,
      "total_sentences": 6,
      "avg_words_per_sentence": 29.5,
      "avg_word_length": 5.242937853107344
    }
  },
  {
    "arxiv_id": "0507044v1",
    "title": "Defensive Universal Learning with Experts",
    "authors": [
      "Jan Poland",
      "Marcus Hutter"
    ],
    "abstract": "This paper shows how universal learning can be achieved with expert advice.\nTo this aim, we specify an experts algorithm with the following\ncharacteristics: (a) it uses only feedback from the actions actually chosen\n(bandit setup), (b) it can be applied with countably infinite expert classes,\nand (c) it copes with losses that may grow in time appropriately slowly. We\nprove loss bounds against an adaptive adversary. From this, we obtain a master\nalgorithm for \"reactive\" experts problems, which means that the master's\nactions may influence the behavior of the adversary. Our algorithm can\nsignificantly outperform standard experts algorithms on such problems. Finally,\nwe combine it with a universal expert class. The resulting universal learner\nperforms -- in a certain sense -- almost as well as any computable strategy,\nfor any online decision problem. We also specify the (worst-case) convergence\nspeed, which is very slow.",
    "categories": [
      "cs.LG",
      "I.2.6; G.3"
    ],
    "published": "2005-07-18T14:33:56Z",
    "updated": "2005-07-18T14:33:56Z",
    "abstract_stats": {
      "total_words": 145,
      "unique_words": 98,
      "total_sentences": 8,
      "avg_words_per_sentence": 18.125,
      "avg_word_length": 5.186206896551724
    }
  },
  {
    "arxiv_id": "0507062v1",
    "title": "FPL Analysis for Adaptive Bandits",
    "authors": [
      "Jan Poland"
    ],
    "abstract": "A main problem of \"Follow the Perturbed Leader\" strategies for online\ndecision problems is that regret bounds are typically proven against oblivious\nadversary. In partial observation cases, it was not clear how to obtain\nperformance guarantees against adaptive adversary, without worsening the\nbounds. We propose a conceptually simple argument to resolve this problem.\nUsing this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed\nbandit problem is shown. This bound holds for the common FPL variant using only\nthe observations from designated exploration rounds. Using all observations\nallows for the stronger bound of O(t^(1/2)), matching the best bound known so\nfar (and essentially the known lower bound) for adversarial bandits.\nSurprisingly, this variant does not even need explicit exploration, it is\nself-stabilizing. However the sampling probabilities have to be either\nexternally provided or approximated to sufficient accuracy, using O(t^2 log t)\nsamples in each step.",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-07-26T05:00:27Z",
    "updated": "2005-07-26T05:00:27Z",
    "abstract_stats": {
      "total_words": 157,
      "unique_words": 103,
      "total_sentences": 8,
      "avg_words_per_sentence": 19.625,
      "avg_word_length": 5.191082802547771
    }
  },
  {
    "arxiv_id": "0509055v1",
    "title": "Learning Optimal Augmented Bayes Networks",
    "authors": [
      "Vikas Hamine",
      "Paul Helman"
    ],
    "abstract": "Naive Bayes is a simple Bayesian classifier with strong independence\nassumptions among the attributes. This classifier, desipte its strong\nindependence assumptions, often performs well in practice. It is believed that\nrelaxing the independence assumptions of a naive Bayes classifier may improve\nthe classification accuracy of the resulting structure. While finding an\noptimal unconstrained Bayesian Network (for most any reasonable scoring\nmeasure) is an NP-hard problem, it is possible to learn in polynomial time\noptimal networks obeying various structural restrictions. Several authors have\nexamined the possibilities of adding augmenting arcs between attributes of a\nNaive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN\nstructure in which the augmenting arcs form a tree on the attributes, and\npresent a polynomial time algorithm that learns an optimal TAN with respect to\nMDL score. Keogh and Pazzani define Augmented Bayes Networks in which the\naugmenting arcs form a forest on the attributes (a collection of trees, hence a\nrelaxation of the stuctural restriction of TAN), and present heuristic search\nmethods for learning good, though not optimal, augmenting arc sets. The\nauthors, however, evaluate the learned structure only in terms of observed\nmisclassification error and not against a scoring metric, such as MDL. In this\npaper, we present a simple, polynomial time greedy algorithm for learning an\noptimal Augmented Bayes Network with respect to MDL score.",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-09-19T04:57:26Z",
    "updated": "2005-09-19T04:57:26Z",
    "abstract_stats": {
      "total_words": 223,
      "unique_words": 117,
      "total_sentences": 9,
      "avg_words_per_sentence": 24.77777777777778,
      "avg_word_length": 5.560538116591928
    }
  },
  {
    "arxiv_id": "0510038v4",
    "title": "Learning Unions of $ω(1)$-Dimensional Rectangles",
    "authors": [
      "Alp Atici",
      "Rocco A. Servedio"
    ],
    "abstract": "We consider the problem of learning unions of rectangles over the domain\n$[b]^n$, in the uniform distribution membership query learning setting, where\nboth b and n are \"large\". We obtain poly$(n, \\log b)$-time algorithms for the\nfollowing classes:\n  - poly$(n \\log b)$-way Majority of $O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log\nb)})$-dimensional rectangles.\n  - Union of poly$(\\log(n \\log b))$ many $O(\\frac{\\log^2 (n \\log b)} {(\\log\n\\log(n \\log b) \\log \\log \\log (n \\log b))^2})$-dimensional rectangles.\n  - poly$(n \\log b)$-way Majority of poly$(n \\log b)$-Or of disjoint\n$O(\\frac{\\log(n \\log b)} {\\log \\log(n \\log b)})$-dimensional rectangles.\n  Our main algorithmic tool is an extension of Jackson's boosting- and\nFourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$,\nbuilding on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to\nobtain the results stated above are techniques from exact learning [Beimel,\nKushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$\ncircuits [Jackson, Klivans, Servedio 2002] and on representing Boolean\nfunctions as thresholds of parities [Klivans, Servedio 2001].",
    "categories": [
      "cs.LG",
      "F.2.2; I.2.6"
    ],
    "published": "2005-10-14T19:26:34Z",
    "updated": "2007-06-26T14:00:17Z",
    "abstract_stats": {
      "total_words": 193,
      "unique_words": 93,
      "total_sentences": 6,
      "avg_words_per_sentence": 32.166666666666664,
      "avg_word_length": 4.341968911917099
    }
  },
  {
    "arxiv_id": "0511058v2",
    "title": "On-line regression competitive with reproducing kernel Hilbert spaces",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "We consider the problem of on-line prediction of real-valued labels, assumed\nbounded in absolute value by a known constant, of new objects from known\nlabeled objects. The prediction algorithm's performance is measured by the\nsquared deviation of the predictions from the actual labels. No stochastic\nassumptions are made about the way the labels and objects are generated.\nInstead, we are given a benchmark class of prediction rules some of which are\nhoped to produce good predictions. We show that for a wide range of\ninfinite-dimensional benchmark classes one can construct a prediction algorithm\nwhose cumulative loss over the first N examples does not exceed the cumulative\nloss of any prediction rule in the class plus O(sqrt(N)); the main differences\nfrom the known results are that we do not impose any upper bound on the norm of\nthe considered prediction rules and that we achieve an optimal leading term in\nthe excess loss of our algorithm. If the benchmark class is \"universal\" (dense\nin the class of continuous functions on each compact set), this provides an\non-line non-stochastic analogue of universally consistent prediction in\nnon-parametric statistics. We use two proof techniques: one is based on the\nAggregating Algorithm and the other on the recently developed method of\ndefensive forecasting.",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-11-15T17:13:50Z",
    "updated": "2006-01-24T23:27:14Z",
    "abstract_stats": {
      "total_words": 217,
      "unique_words": 123,
      "total_sentences": 7,
      "avg_words_per_sentence": 31.0,
      "avg_word_length": 4.967741935483871
    }
  },
  {
    "arxiv_id": "0511088v1",
    "title": "Bounds on Query Convergence",
    "authors": [
      "Barak A. Pearlmutter"
    ],
    "abstract": "The problem of finding an optimum using noisy evaluations of a smooth cost\nfunction arises in many contexts, including economics, business, medicine,\nexperiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -\nx*)^2 ] >= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,\n>...) generated by an unbiased feedback process observing noisy evaluations of\nan unknown quadratic function maximised at x*. The bound is tight, as the proof\nleads to a simple algorithm which meets it. We further establish a bound on the\ntotal regret, E[ sum_{i=1..t} (x_i - x*)^2 ] >= O(sqrt(t)) These bounds may\nimpose practical limitations on an agent's performance, as O(eps^-4) queries\nare made before the queries converge to x* with eps accuracy.",
    "categories": [
      "cs.LG",
      "G.1.6"
    ],
    "published": "2005-11-25T15:57:56Z",
    "updated": "2005-11-25T15:57:56Z",
    "abstract_stats": {
      "total_words": 129,
      "unique_words": 90,
      "total_sentences": 6,
      "avg_words_per_sentence": 21.5,
      "avg_word_length": 4.48062015503876
    }
  },
  {
    "arxiv_id": "0512050v1",
    "title": "Preference Learning in Terminology Extraction: A ROC-based approach",
    "authors": [
      "Jérôme Azé",
      "Mathieu Roche",
      "Yves Kodratoff",
      "Michèle Sebag"
    ],
    "abstract": "A key data preparation step in Text Mining, Term Extraction selects the\nterms, or collocation of words, attached to specific concepts. In this paper,\nthe task of extracting relevant collocations is achieved through a supervised\nlearning algorithm, exploiting a few collocations manually labelled as\nrelevant/irrelevant. The candidate terms are described along 13 standard\nstatistical criteria measures. From these examples, an evolutionary learning\nalgorithm termed Roger, based on the optimization of the Area under the ROC\ncurve criterion, extracts an order on the candidate terms. The robustness of\nthe approach is demonstrated on two real-world domain applications, considering\ndifferent domains (biology and human resources) and different languages\n(English and French).",
    "categories": [
      "cs.LG"
    ],
    "published": "2005-12-13T13:25:57Z",
    "updated": "2005-12-13T13:25:57Z",
    "abstract_stats": {
      "total_words": 111,
      "unique_words": 83,
      "total_sentences": 5,
      "avg_words_per_sentence": 22.2,
      "avg_word_length": 5.828828828828829
    }
  },
  {
    "arxiv_id": "0512059v2",
    "title": "Competing with wild prediction rules",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "We consider the problem of on-line prediction competitive with a benchmark\nclass of continuous but highly irregular prediction rules. It is known that if\nthe benchmark class is a reproducing kernel Hilbert space, there exists a\nprediction algorithm whose average loss over the first N examples does not\nexceed the average loss of any prediction rule in the class plus a \"regret\nterm\" of O(N^(-1/2)). The elements of some natural benchmark classes, however,\nare so irregular that these classes are not Hilbert spaces. In this paper we\ndevelop Banach-space methods to construct a prediction algorithm with a regret\nterm of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to\nwhich the benchmark class fails to be a Hilbert space.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2005-12-14T20:03:30Z",
    "updated": "2006-01-25T17:36:52Z",
    "abstract_stats": {
      "total_words": 132,
      "unique_words": 74,
      "total_sentences": 4,
      "avg_words_per_sentence": 33.0,
      "avg_word_length": 4.484848484848484
    }
  },
  {
    "arxiv_id": "0601044v1",
    "title": "Genetic Programming, Validation Sets, and Parsimony Pressure",
    "authors": [
      "Christian Gagné",
      "Marc Schoenauer",
      "Marc Parizeau",
      "Marco Tomassini"
    ],
    "abstract": "Fitness functions based on test cases are very common in Genetic Programming\n(GP). This process can be assimilated to a learning task, with the inference of\nmodels from a limited number of samples. This paper is an investigation on two\nmethods to improve generalization in GP-based learning: 1) the selection of the\nbest-of-run individuals using a three data sets methodology, and 2) the\napplication of parsimony pressure in order to reduce the complexity of the\nsolutions. Results using GP in a binary classification setup show that while\nthe accuracy on the test sets is preserved, with less variances compared to\nbaseline results, the mean tree size obtained with the tested methods is\nsignificantly reduced.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-01-11T15:39:16Z",
    "updated": "2006-01-11T15:39:16Z",
    "abstract_stats": {
      "total_words": 117,
      "unique_words": 78,
      "total_sentences": 4,
      "avg_words_per_sentence": 29.25,
      "avg_word_length": 4.9743589743589745
    }
  },
  {
    "arxiv_id": "0601087v1",
    "title": "Processing of Test Matrices with Guessing Correction",
    "authors": [
      "Kromer Victor"
    ],
    "abstract": "It is suggested to insert into test matrix 1s for correct responses, 0s for\nresponse refusals, and negative corrective elements for incorrect responses.\nWith the classical test theory approach test scores of examinees and items are\ncalculated traditionally as sums of matrix elements, organized in rows and\ncolumns. Correlation coefficients are estimated using correction coefficients.\nIn item response theory approach examinee and item logits are estimated using\nmaximum likelihood method and probabilities of all matrix elements.",
    "categories": [
      "cs.LG",
      "I.2.6; K.3.2"
    ],
    "published": "2006-01-20T05:40:44Z",
    "updated": "2006-01-20T05:40:44Z",
    "abstract_stats": {
      "total_words": 76,
      "unique_words": 51,
      "total_sentences": 4,
      "avg_words_per_sentence": 19.0,
      "avg_word_length": 5.907894736842105
    }
  },
  {
    "arxiv_id": "0602062v1",
    "title": "Learning rational stochastic languages",
    "authors": [
      "François Denis",
      "Yann Esposito",
      "Amaury Habrard"
    ],
    "abstract": "Given a finite set of words w1,...,wn independently drawn according to a\nfixed unknown distribution law P called a stochastic language, an usual goal in\nGrammatical Inference is to infer an estimate of P in some class of\nprobabilistic models, such as Probabilistic Automata (PA). Here, we study the\nclass of rational stochastic languages, which consists in stochastic languages\nthat can be generated by Multiplicity Automata (MA) and which strictly includes\nthe class of stochastic languages generated by PA. Rational stochastic\nlanguages have minimal normal representation which may be very concise, and\nwhose parameters can be efficiently estimated from stochastic samples. We\ndesign an efficient inference algorithm DEES which aims at building a minimal\nnormal representation of the target. Despite the fact that no recursively\nenumerable class of MA computes exactly the set of rational stochastic\nlanguages over Q, we show that DEES strongly identifies tis set in the limit.\nWe study the intermediary MA output by DEES and show that they compute rational\nseries which converge absolutely to one and which can be used to provide\nstochastic languages which closely estimate the target.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-02-17T08:57:44Z",
    "updated": "2006-02-17T08:57:44Z",
    "abstract_stats": {
      "total_words": 185,
      "unique_words": 101,
      "total_sentences": 7,
      "avg_words_per_sentence": 26.428571428571427,
      "avg_word_length": 5.318918918918919
    }
  },
  {
    "arxiv_id": "0605040v1",
    "title": "General Discounting versus Average Reward",
    "authors": [
      "Marcus Hutter"
    ],
    "abstract": "Consider an agent interacting with an environment in cycles. In every\ninteraction cycle the agent is rewarded for its performance. We compare the\naverage reward U from cycle 1 to m (average value) with the future discounted\nreward V from cycle k to infinity (discounted value). We consider essentially\narbitrary (non-geometric) discount sequences and arbitrary reward sequences\n(non-MDP environments). We show that asymptotically U for m->infinity and V for\nk->infinity are equal, provided both limits exist. Further, if the effective\nhorizon grows linearly with k or faster, then existence of the limit of U\nimplies that the limit of V exists. Conversely, if the effective horizon grows\nlinearly with k or slower, then existence of the limit of V implies that the\nlimit of U exists.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-05-09T10:39:03Z",
    "updated": "2006-05-09T10:39:03Z",
    "abstract_stats": {
      "total_words": 130,
      "unique_words": 66,
      "total_sentences": 7,
      "avg_words_per_sentence": 18.571428571428573,
      "avg_word_length": 4.861538461538461
    }
  },
  {
    "arxiv_id": "0606077v1",
    "title": "On Sequence Prediction for Arbitrary Measures",
    "authors": [
      "Daniil Ryabko",
      "Marcus Hutter"
    ],
    "abstract": "Suppose we are given two probability measures on the set of one-way infinite\nfinite-alphabet sequences and consider the question when one of the measures\npredicts the other, that is, when conditional probabilities converge (in a\ncertain sense) when one of the measures is chosen to generate the sequence.\nThis question may be considered a refinement of the problem of sequence\nprediction in its most general formulation: for a given class of probability\nmeasures, does there exist a measure which predicts all of the measures in the\nclass? To address this problem, we find some conditions on local absolute\ncontinuity which are sufficient for prediction and which generalize several\ndifferent notions which are known to be sufficient for prediction. We also\nformulate some open questions to outline a direction for finding the conditions\non classes of measures for which prediction is possible.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-06-16T16:33:23Z",
    "updated": "2006-06-16T16:33:23Z",
    "abstract_stats": {
      "total_words": 143,
      "unique_words": 77,
      "total_sentences": 4,
      "avg_words_per_sentence": 35.75,
      "avg_word_length": 5.181818181818182
    }
  },
  {
    "arxiv_id": "0606093v1",
    "title": "Predictions as statements and decisions",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "Prediction is a complex notion, and different predictors (such as people,\ncomputer programs, and probabilistic theories) can pursue very different goals.\nIn this paper I will review some popular kinds of prediction and argue that the\ntheory of competitive on-line learning can benefit from the kinds of prediction\nthat are now foreign to it.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-06-22T04:31:51Z",
    "updated": "2006-06-22T04:31:51Z",
    "abstract_stats": {
      "total_words": 55,
      "unique_words": 44,
      "total_sentences": 2,
      "avg_words_per_sentence": 27.5,
      "avg_word_length": 5.090909090909091
    }
  },
  {
    "arxiv_id": "0607047v1",
    "title": "PAC Classification based on PAC Estimates of Label Class Distributions",
    "authors": [
      "Nick Palmer",
      "Paul W. Goldberg"
    ],
    "abstract": "A standard approach in pattern classification is to estimate the\ndistributions of the label classes, and then to apply the Bayes classifier to\nthe estimates of the distributions in order to classify unlabeled examples. As\none might expect, the better our estimates of the label class distributions,\nthe better the resulting classifier will be. In this paper we make this\nobservation precise by identifying risk bounds of a classifier in terms of the\nquality of the estimates of the label class distributions. We show how PAC\nlearnability relates to estimates of the distributions that have a PAC\nguarantee on their $L_1$ distance from the true distribution, and we bound the\nincrease in negative log likelihood risk in terms of PAC bounds on the\nKL-divergence. We give an inefficient but general-purpose smoothing method for\nconverting an estimated distribution that is good under the $L_1$ metric into a\ndistribution that is good under the KL-divergence.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-11T13:52:39Z",
    "updated": "2006-07-11T13:52:39Z",
    "abstract_stats": {
      "total_words": 156,
      "unique_words": 83,
      "total_sentences": 5,
      "avg_words_per_sentence": 31.2,
      "avg_word_length": 5.044871794871795
    }
  },
  {
    "arxiv_id": "0607067v1",
    "title": "Competing with stationary prediction strategies",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "In this paper we introduce the class of stationary prediction strategies and\nconstruct a prediction algorithm that asymptotically performs as well as the\nbest continuous stationary strategy. We make mild compactness assumptions but\nno stochastic assumptions about the environment. In particular, no assumption\nof stationarity is made about the environment, and the stationarity of the\nconsidered strategies only means that they do not depend explicitly on time; we\nargue that it is natural to consider only stationary strategies even for highly\nnon-stationary environments.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-13T15:52:04Z",
    "updated": "2006-07-13T15:52:04Z",
    "abstract_stats": {
      "total_words": 84,
      "unique_words": 57,
      "total_sentences": 3,
      "avg_words_per_sentence": 28.0,
      "avg_word_length": 5.761904761904762
    }
  },
  {
    "arxiv_id": "0607085v2",
    "title": "Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical\n  Inference",
    "authors": [
      "Amaury Habrard",
      "Francois Denis",
      "Yann Esposito"
    ],
    "abstract": "In probabilistic grammatical inference, a usual goal is to infer a good\napproximation of an unknown distribution P called a stochastic language. The\nestimate of P stands in some class of probabilistic models such as\nprobabilistic automata (PA). In this paper, we focus on probabilistic models\nbased on multiplicity automata (MA). The stochastic languages generated by MA\nare called rational stochastic languages; they strictly include stochastic\nlanguages generated by PA; they also admit a very concise canonical\nrepresentation. Despite the fact that this class is not recursively enumerable,\nit is efficiently identifiable in the limit by using the algorithm DEES,\nintroduced by the authors in a previous paper. However, the identification is\nnot proper and before the convergence of the algorithm, DEES can produce MA\nthat do not define stochastic languages. Nevertheless, it is possible to use\nthese MA to define stochastic languages. We show that they belong to a broader\nclass of rational series, that we call pseudo-stochastic rational languages.\nThe aim of this paper is twofold. First we provide a theoretical study of\npseudo-stochastic rational languages, the languages output by DEES, showing for\nexample that this class is decidable within polynomial time. Second, we have\ncarried out a lot of experiments in order to compare DEES to classical\ninference algorithms such as ALERGIA and MDI. They show that DEES outperforms\nthem in most cases.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-18T07:21:51Z",
    "updated": "2008-11-07T16:21:18Z",
    "abstract_stats": {
      "total_words": 228,
      "unique_words": 118,
      "total_sentences": 12,
      "avg_words_per_sentence": 19.0,
      "avg_word_length": 5.25
    }
  },
  {
    "arxiv_id": "0607096v1",
    "title": "Logical settings for concept learning from incomplete examples in First\n  Order Logic",
    "authors": [
      "Dominique Bouthinon",
      "Henry Soldano",
      "Véronique Ventos"
    ],
    "abstract": "We investigate here concept learning from incomplete examples. Our first\npurpose is to discuss to what extent logical learning settings have to be\nmodified in order to cope with data incompleteness. More precisely we are\ninterested in extending the learning from interpretations setting introduced by\nL. De Raedt that extends to relational representations the classical\npropositional (or attribute-value) concept learning from examples framework. We\nare inspired here by ideas presented by H. Hirsh in a work extending the\nVersion space inductive paradigm to incomplete data. H. Hirsh proposes to\nslightly modify the notion of solution when dealing with incomplete examples: a\nsolution has to be a hypothesis compatible with all pieces of information\nconcerning the examples. We identify two main classes of incompleteness. First,\nuncertainty deals with our state of knowledge concerning an example. Second,\ngeneralization (or abstraction) deals with what part of the description of the\nexample is sufficient for the learning purpose. These two main sources of\nincompleteness can be mixed up when only part of the useful information is\nknown. We discuss a general learning setting, referred to as \"learning from\npossibilities\" that formalizes these ideas, then we present a more specific\nlearning setting, referred to as \"assumption-based learning\" that cope with\nexamples which uncertainty can be reduced when considering contextual\ninformation outside of the proper description of the examples. Assumption-based\nlearning is illustrated on a recent work concerning the prediction of a\nconsensus secondary structure common to a set of RNA sequences.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-20T14:52:08Z",
    "updated": "2006-07-20T14:52:08Z",
    "abstract_stats": {
      "total_words": 249,
      "unique_words": 128,
      "total_sentences": 14,
      "avg_words_per_sentence": 17.785714285714285,
      "avg_word_length": 5.514056224899599
    }
  },
  {
    "arxiv_id": "0607110v1",
    "title": "A Theory of Probabilistic Boosting, Decision Trees and Matryoshki",
    "authors": [
      "Etienne Grossmann"
    ],
    "abstract": "We present a theory of boosting probabilistic classifiers. We place ourselves\nin the situation of a user who only provides a stopping parameter and a\nprobabilistic weak learner/classifier and compare three types of boosting\nalgorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of\ntrees, which we call matryoshka. \"Nested tree,\" \"embedded tree\" and \"recursive\ntree\" are also appropriate names for this algorithm, which is one of our\ncontributions. Our other contribution is the theoretical analysis of the\nalgorithms, in which we give training error bounds. This analysis suggests that\nthe matryoshka leverages probabilistic weak classifiers more efficiently than\nsimple decision trees.",
    "categories": [
      "cs.LG",
      "I.5.1; I.2.6; G.3"
    ],
    "published": "2006-07-25T15:57:56Z",
    "updated": "2006-07-25T15:57:56Z",
    "abstract_stats": {
      "total_words": 104,
      "unique_words": 63,
      "total_sentences": 6,
      "avg_words_per_sentence": 17.333333333333332,
      "avg_word_length": 5.605769230769231
    }
  },
  {
    "arxiv_id": "0607134v1",
    "title": "Leading strategies in competitive on-line prediction",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "We start from a simple asymptotic result for the problem of on-line\nregression with the quadratic loss function: the class of continuous\nlimited-memory prediction strategies admits a \"leading prediction strategy\",\nwhich not only asymptotically performs at least as well as any continuous\nlimited-memory strategy but also satisfies the property that the excess loss of\nany continuous limited-memory strategy is determined by how closely it imitates\nthe leading strategy. More specifically, for any class of prediction strategies\nconstituting a reproducing kernel Hilbert space we construct a leading\nstrategy, in the sense that the loss of any prediction strategy whose norm is\nnot too large is determined by how closely it imitates the leading strategy.\nThis result is extended to the loss functions given by Bregman divergences and\nby strictly proper scoring rules.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-27T22:11:07Z",
    "updated": "2006-07-27T22:11:07Z",
    "abstract_stats": {
      "total_words": 135,
      "unique_words": 76,
      "total_sentences": 3,
      "avg_words_per_sentence": 45.0,
      "avg_word_length": 5.355555555555555
    }
  },
  {
    "arxiv_id": "0607136v1",
    "title": "Competing with Markov prediction strategies",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "Assuming that the loss function is convex in the prediction, we construct a\nprediction strategy universal for the class of Markov prediction strategies,\nnot necessarily continuous. Allowing randomization, we remove the requirement\nof convexity.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-07-28T21:45:41Z",
    "updated": "2006-07-28T21:45:41Z",
    "abstract_stats": {
      "total_words": 34,
      "unique_words": 27,
      "total_sentences": 2,
      "avg_words_per_sentence": 17.0,
      "avg_word_length": 6.0588235294117645
    }
  },
  {
    "arxiv_id": "0608033v1",
    "title": "A Study on Learnability for Rigid Lambek Grammars",
    "authors": [
      "Roberto Bonato"
    ],
    "abstract": "We present basic notions of Gold's \"learnability in the limit\" paradigm,\nfirst presented in 1967, a formalization of the cognitive process by which a\nnative speaker gets to grasp the underlying grammar of his/her own native\nlanguage by being exposed to well formed sentences generated by that grammar.\nThen we present Lambek grammars, a formalism issued from categorial grammars\nwhich, although not as expressive as needed for a full formalization of natural\nlanguages, is particularly suited to easily implement a natural interface\nbetween syntax and semantics. In the last part of this work, we present a\nlearnability result for Rigid Lambek grammars from structured examples.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-08-06T16:10:05Z",
    "updated": "2006-08-06T16:10:05Z",
    "abstract_stats": {
      "total_words": 107,
      "unique_words": 73,
      "total_sentences": 3,
      "avg_words_per_sentence": 35.666666666666664,
      "avg_word_length": 5.242990654205608
    }
  },
  {
    "arxiv_id": "0609007v1",
    "title": "A Massive Local Rules Search Approach to the Classification Problem",
    "authors": [
      "Vladislav Malyshkin",
      "Ray Bakhramov",
      "Andrey Gorodetsky"
    ],
    "abstract": "An approach to the classification problem of machine learning, based on\nbuilding local classification rules, is developed. The local rules are\nconsidered as projections of the global classification rules to the event we\nwant to classify. A massive global optimization algorithm is used for\noptimization of quality criterion. The algorithm, which has polynomial\ncomplexity in typical case, is used to find all high--quality local rules. The\nother distinctive feature of the algorithm is the integration of attributes\nlevels selection (for ordered attributes) with rules searching and original\nconflicting rules resolution strategy. The algorithm is practical; it was\ntested on a number of data sets from UCI repository, and a comparison with the\nother predicting techniques is presented.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-09-03T21:30:03Z",
    "updated": "2006-09-03T21:30:03Z",
    "abstract_stats": {
      "total_words": 118,
      "unique_words": 72,
      "total_sentences": 6,
      "avg_words_per_sentence": 19.666666666666668,
      "avg_word_length": 5.5423728813559325
    }
  },
  {
    "arxiv_id": "0609045v1",
    "title": "Metric entropy in competitive on-line prediction",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "Competitive on-line prediction (also known as universal prediction of\nindividual sequences) is a strand of learning theory avoiding making any\nstochastic assumptions about the way the observations are generated. The\npredictor's goal is to compete with a benchmark class of prediction rules,\nwhich is often a proper Banach function space. Metric entropy provides a\nunifying framework for competitive on-line prediction: the numerous known upper\nbounds on the metric entropy of various compact sets in function spaces readily\nimply bounds on the performance of on-line prediction strategies. This paper\ndiscusses strengths and limitations of the direct approach to competitive\non-line prediction via metric entropy, including comparisons to other\napproaches.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-09-09T11:31:01Z",
    "updated": "2006-09-09T11:31:01Z",
    "abstract_stats": {
      "total_words": 113,
      "unique_words": 73,
      "total_sentences": 4,
      "avg_words_per_sentence": 28.25,
      "avg_word_length": 5.619469026548672
    }
  },
  {
    "arxiv_id": "0609093v1",
    "title": "PAC Learning Mixtures of Axis-Aligned Gaussians with No Separation\n  Assumption",
    "authors": [
      "Jon Feldman",
      "Ryan O'Donnell",
      "Rocco A. Servedio"
    ],
    "abstract": "We propose and analyze a new vantage point for the learning of mixtures of\nGaussians: namely, the PAC-style model of learning probability distributions\nintroduced by Kearns et al. Here the task is to construct a hypothesis mixture\nof Gaussians that is statistically indistinguishable from the actual mixture\ngenerating the data; specifically, the KL-divergence should be at most epsilon.\n  In this scenario, we give a poly(n/epsilon)-time algorithm that learns the\nclass of mixtures of any constant number of axis-aligned Gaussians in\nn-dimensional Euclidean space. Our algorithm makes no assumptions about the\nseparation between the means of the Gaussians, nor does it have any dependence\non the minimum mixing weight. This is in contrast to learning results known in\nthe ``clustering'' model, where such assumptions are unavoidable.\n  Our algorithm relies on the method of moments, and a subalgorithm developed\nin previous work by the authors (FOCS 2005) for a discrete mixture-learning\nproblem.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-09-16T14:43:27Z",
    "updated": "2006-09-16T14:43:27Z",
    "abstract_stats": {
      "total_words": 158,
      "unique_words": 102,
      "total_sentences": 6,
      "avg_words_per_sentence": 26.333333333333332,
      "avg_word_length": 5.158227848101266
    }
  },
  {
    "arxiv_id": "0611011v1",
    "title": "Hedging predictions in machine learning",
    "authors": [
      "Alexander Gammerman",
      "Vladimir Vovk"
    ],
    "abstract": "Recent advances in machine learning make it possible to design efficient\nprediction algorithms for data sets with huge numbers of parameters. This paper\ndescribes a new technique for \"hedging\" the predictions output by many such\nalgorithms, including support vector machines, kernel ridge regression, kernel\nnearest neighbours, and by many other state-of-the-art methods. The hedged\npredictions for the labels of new objects include quantitative measures of\ntheir own accuracy and reliability. These measures are provably valid under the\nassumption of randomness, traditional in machine learning: the objects and\ntheir labels are assumed to be generated independently from the same\nprobability distribution. In particular, it becomes possible to control (up to\nstatistical fluctuations) the number of erroneous predictions by selecting a\nsuitable confidence level. Validity being achieved automatically, the remaining\ngoal of hedged prediction is efficiency: taking full account of the new\nobjects' features and other available information to produce as accurate\npredictions as possible. This can be done successfully using the powerful\nmachinery of modern machine learning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-11-02T18:44:49Z",
    "updated": "2006-11-02T18:44:49Z",
    "abstract_stats": {
      "total_words": 169,
      "unique_words": 110,
      "total_sentences": 7,
      "avg_words_per_sentence": 24.142857142857142,
      "avg_word_length": 5.828402366863905
    }
  },
  {
    "arxiv_id": "0611145v1",
    "title": "A Unified View of TD Algorithms; Introducing Full-Gradient TD and\n  Equi-Gradient Descent TD",
    "authors": [
      "Manuel Loth",
      "Philippe Preux"
    ],
    "abstract": "This paper addresses the issue of policy evaluation in Markov Decision\nProcesses, using linear function approximation. It provides a unified view of\nalgorithms such as TD(lambda), LSTD(lambda), iLSTD, residual-gradient TD. It is\nasserted that they all consist in minimizing a gradient function and differ by\nthe form of this function and their means of minimizing it. Two new schemes are\nintroduced in that framework: Full-gradient TD which uses a generalization of\nthe principle introduced in iLSTD, and EGD TD, which reduces the gradient by\nsuccessive equi-gradient descents. These three algorithms form a new\nintermediate family with the interesting property of making much better use of\nthe samples than TD while keeping a gradient descent scheme, which is useful\nfor complexity issues and optimistic policy iteration.",
    "categories": [
      "cs.LG"
    ],
    "published": "2006-11-29T00:00:57Z",
    "updated": "2006-11-29T00:00:57Z",
    "abstract_stats": {
      "total_words": 130,
      "unique_words": 82,
      "total_sentences": 5,
      "avg_words_per_sentence": 26.0,
      "avg_word_length": 5.2153846153846155
    }
  },
  {
    "arxiv_id": "0703062v1",
    "title": "Bandit Algorithms for Tree Search",
    "authors": [
      "Pierre-Arnaud Coquelin",
      "Rémi Munos"
    ],
    "abstract": "Bandit based methods for tree search have recently gained popularity when\napplied to huge trees, e.g. in the game of go (Gelly et al., 2006). The UCT\nalgorithm (Kocsis and Szepesvari, 2006), a tree search method based on Upper\nConfidence Bounds (UCB) (Auer et al., 2002), is believed to adapt locally to\nthe effective smoothness of the tree. However, we show that UCT is too\n``optimistic'' in some cases, leading to a regret O(exp(exp(D))) where D is the\ndepth of the tree. We propose alternative bandit algorithms for tree search.\nFirst, a modification of UCT using a confidence sequence that scales\nexponentially with the horizon depth is proven to have a regret O(2^D\n\\sqrt{n}), but does not adapt to possible smoothness in the tree. We then\nanalyze Flat-UCB performed on the leaves and provide a finite regret bound with\nhigh probability. Then, we introduce a UCB-based Bandit Algorithm for Smooth\nTrees which takes into account actual smoothness of the rewards for performing\nefficient ``cuts'' of sub-optimal branches with high confidence. Finally, we\npresent an incremental tree search version which applies when the full tree is\ntoo big (possibly infinite) to be entirely represented and show that with high\nprobability, essentially only the optimal branches is indefinitely developed.\nWe illustrate these methods on a global optimization problem of a Lipschitz\nfunction, given noisy data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-03-13T08:53:41Z",
    "updated": "2007-03-13T08:53:41Z",
    "abstract_stats": {
      "total_words": 233,
      "unique_words": 131,
      "total_sentences": 13,
      "avg_words_per_sentence": 17.923076923076923,
      "avg_word_length": 4.785407725321888
    }
  },
  {
    "arxiv_id": "0703125v1",
    "title": "Intrinsic dimension of a dataset: what properties does one expect?",
    "authors": [
      "Vladimir Pestov"
    ],
    "abstract": "We propose an axiomatic approach to the concept of an intrinsic dimension of\na dataset, based on a viewpoint of geometry of high-dimensional structures. Our\nfirst axiom postulates that high values of dimension be indicative of the\npresence of the curse of dimensionality (in a certain precise mathematical\nsense). The second axiom requires the dimension to depend smoothly on a\ndistance between datasets (so that the dimension of a dataset and that of an\napproximating principal manifold would be close to each other). The third axiom\nis a normalization condition: the dimension of the Euclidean $n$-sphere $\\s^n$\nis $\\Theta(n)$. We give an example of a dimension function satisfying our\naxioms, even though it is in general computationally unfeasible, and discuss a\ncomputationally cheap function satisfying most but not all of our axioms (the\n``intrinsic dimensionality'' of Ch\\'avez et al.)",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-03-25T01:19:14Z",
    "updated": "2007-03-25T01:19:14Z",
    "abstract_stats": {
      "total_words": 144,
      "unique_words": 82,
      "total_sentences": 6,
      "avg_words_per_sentence": 24.0,
      "avg_word_length": 5.006944444444445
    }
  },
  {
    "arxiv_id": "0704.1274v1",
    "title": "Parametric Learning and Monte Carlo Optimization",
    "authors": [
      "David H. Wolpert",
      "Dev G. Rajnarayan"
    ],
    "abstract": "This paper uncovers and explores the close relationship between Monte Carlo\nOptimization of a parametrized integral (MCO), Parametric machine-Learning\n(PL), and `blackbox' or `oracle'-based optimization (BO). We make four\ncontributions. First, we prove that MCO is mathematically identical to a broad\nclass of PL problems. This identity potentially provides a new application\ndomain for all broadly applicable PL techniques: MCO. Second, we introduce\nimmediate sampling, a new version of the Probability Collectives (PC) algorithm\nfor blackbox optimization. Immediate sampling transforms the original BO\nproblem into an MCO problem. Accordingly, by combining these first two\ncontributions, we can apply all PL techniques to BO. In our third contribution\nwe validate this way of improving BO by demonstrating that cross-validation and\nbagging improve immediate sampling. Finally, conventional MC and MCO procedures\nignore the relationship between the sample point locations and the associated\nvalues of the integrand; only the values of the integrand at those locations\nare considered. We demonstrate that one can exploit the sample location\ninformation using PL techniques, for example by forming a fit of the sample\nlocations to the associated values of the integrand. This provides an\nadditional way to apply PL techniques to improve MCO.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-04-10T17:01:07Z",
    "updated": "2007-04-10T17:01:07Z",
    "abstract_stats": {
      "total_words": 200,
      "unique_words": 110,
      "total_sentences": 11,
      "avg_words_per_sentence": 18.181818181818183,
      "avg_word_length": 5.535
    }
  },
  {
    "arxiv_id": "0704.2668v1",
    "title": "Supervised Feature Selection via Dependence Estimation",
    "authors": [
      "Le Song",
      "Alex Smola",
      "Arthur Gretton",
      "Karsten Borgwardt",
      "Justin Bedo"
    ],
    "abstract": "We introduce a framework for filtering features that employs the\nHilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence\nbetween the features and the labels. The key idea is that good features should\nmaximise such dependence. Feature selection for various supervised learning\nproblems (including classification and regression) is unified under this\nframework, and the solutions can be approximated using a backward-elimination\nalgorithm. We demonstrate the usefulness of our method on both artificial and\nreal world datasets.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-04-20T08:26:29Z",
    "updated": "2007-04-20T08:26:29Z",
    "abstract_stats": {
      "total_words": 78,
      "unique_words": 59,
      "total_sentences": 4,
      "avg_words_per_sentence": 19.5,
      "avg_word_length": 5.846153846153846
    }
  },
  {
    "arxiv_id": "0705.1585v1",
    "title": "HMM Speaker Identification Using Linear and Non-linear Merging\n  Techniques",
    "authors": [
      "Unathi Mahola",
      "Fulufhelo V. Nelwamondo",
      "Tshilidzi Marwala"
    ],
    "abstract": "Speaker identification is a powerful, non-invasive and in-expensive biometric\ntechnique. The recognition accuracy, however, deteriorates when noise levels\naffect a specific band of frequency. In this paper, we present a sub-band based\nspeaker identification that intends to improve the live testing performance.\nEach frequency sub-band is processed and classified independently. We also\ncompare the linear and non-linear merging techniques for the sub-bands\nrecognizer. Support vector machines and Gaussian Mixture models are the\nnon-linear merging techniques that are investigated. Results showed that the\nsub-band based method used with linear merging techniques enormously improved\nthe performance of the speaker identification over the performance of wide-band\nrecognizers when tested live. A live testing improvement of 9.78% was achieved",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-05-11T04:54:54Z",
    "updated": "2007-05-11T04:54:54Z",
    "abstract_stats": {
      "total_words": 125,
      "unique_words": 74,
      "total_sentences": 9,
      "avg_words_per_sentence": 13.88888888888889,
      "avg_word_length": 5.656
    }
  },
  {
    "arxiv_id": "0706.3679v1",
    "title": "Scale-sensitive Psi-dimensions: the Capacity Measures for Classifiers\n  Taking Values in R^Q",
    "authors": [
      "Yann Guermeur"
    ],
    "abstract": "Bounds on the risk play a crucial role in statistical learning theory. They\nusually involve as capacity measure of the model studied the VC dimension or\none of its extensions. In classification, such \"VC dimensions\" exist for models\ntaking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations\nappropriate for the missing case, the one of models with values in R^Q. This\nprovides us with a new guaranteed risk for M-SVMs which appears superior to the\nexisting one.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-06-25T17:28:57Z",
    "updated": "2007-06-25T17:28:57Z",
    "abstract_stats": {
      "total_words": 83,
      "unique_words": 59,
      "total_sentences": 6,
      "avg_words_per_sentence": 13.833333333333334,
      "avg_word_length": 4.542168674698795
    }
  },
  {
    "arxiv_id": "0707.3390v2",
    "title": "Consistency of the group Lasso and multiple kernel learning",
    "authors": [
      "Francis Bach"
    ],
    "abstract": "We consider the least-square regression problem with regularization by a\nblock 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger\nthan one. This problem, referred to as the group Lasso, extends the usual\nregularization by the 1-norm where all spaces have dimension one, where it is\ncommonly referred to as the Lasso. In this paper, we study the asymptotic model\nconsistency of the group Lasso. We derive necessary and sufficient conditions\nfor the consistency of group Lasso under practical assumptions, such as model\nmisspecification. When the linear predictors and Euclidean norms are replaced\nby functions and reproducing kernel Hilbert norms, the problem is usually\nreferred to as multiple kernel learning and is commonly used for learning from\nheterogeneous data sources and for non linear variable selection. Using tools\nfrom functional analysis, and in particular covariance operators, we extend the\nconsistency results to this infinite dimensional case and also propose an\nadaptive scheme to obtain a consistent model estimate, even when the necessary\ncondition required for the non adaptive scheme is not satisfied.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-07-23T14:35:20Z",
    "updated": "2008-01-28T10:10:31Z",
    "abstract_stats": {
      "total_words": 179,
      "unique_words": 103,
      "total_sentences": 8,
      "avg_words_per_sentence": 22.375,
      "avg_word_length": 5.301675977653631
    }
  },
  {
    "arxiv_id": "0708.1242v3",
    "title": "Cost-minimising strategies for data labelling : optimal stopping and\n  active learning",
    "authors": [
      "Christos Dimitrakakis",
      "Christian Savu-Krohn"
    ],
    "abstract": "Supervised learning deals with the inference of a distribution over an output\nor label space $\\CY$ conditioned on points in an observation space $\\CX$, given\na training dataset $D$ of pairs in $\\CX \\times \\CY$. However, in a lot of\napplications of interest, acquisition of large amounts of observations is easy,\nwhile the process of generating labels is time-consuming or costly. One way to\ndeal with this problem is {\\em active} learning, where points to be labelled\nare selected with the aim of creating a model with better performance than that\nof an model trained on an equal number of randomly sampled points. In this\npaper, we instead propose to deal with the labelling cost directly: The\nlearning goal is defined as the minimisation of a cost which is a function of\nthe expected model performance and the total cost of the labels used. This\nallows the development of general strategies and specific algorithms for (a)\noptimal stopping, where the expected cost dictates whether label acquisition\nshould continue (b) empirical evaluation, where the cost is used as a\nperformance metric for a given combination of inference, stopping and sampling\nmethods. Though the main focus of the paper is optimal stopping, we also aim to\nprovide the background for further developments and discussion in the related\nfield of active learning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-08-09T10:21:34Z",
    "updated": "2007-11-15T16:37:51Z",
    "abstract_stats": {
      "total_words": 220,
      "unique_words": 118,
      "total_sentences": 6,
      "avg_words_per_sentence": 36.666666666666664,
      "avg_word_length": 4.9
    }
  },
  {
    "arxiv_id": "0708.1503v1",
    "title": "Defensive forecasting for optimal prediction with expert advice",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "The method of defensive forecasting is applied to the problem of prediction\nwith expert advice for binary outcomes. It turns out that defensive forecasting\nis not only competitive with the Aggregating Algorithm but also handles the\ncase of \"second-guessing\" experts, whose advice depends on the learner's\nprediction; this paper assumes that the dependence on the learner's prediction\nis continuous.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-08-10T19:19:54Z",
    "updated": "2007-08-10T19:19:54Z",
    "abstract_stats": {
      "total_words": 62,
      "unique_words": 42,
      "total_sentences": 2,
      "avg_words_per_sentence": 31.0,
      "avg_word_length": 5.338709677419355
    }
  },
  {
    "arxiv_id": "0708.2353v2",
    "title": "Continuous and randomized defensive forecasting: unified view",
    "authors": [
      "Vladimir Vovk"
    ],
    "abstract": "Defensive forecasting is a method of transforming laws of probability (stated\nin game-theoretic terms as strategies for Sceptic) into forecasting algorithms.\nThere are two known varieties of defensive forecasting: \"continuous\", in which\nSceptic's moves are assumed to depend on the forecasts in a (semi)continuous\nmanner and which produces deterministic forecasts, and \"randomized\", in which\nthe dependence of Sceptic's moves on the forecasts is arbitrary and\nForecaster's moves are allowed to be randomized. This note shows that the\nrandomized variety can be obtained from the continuous variety by smearing\nSceptic's moves to make them continuous.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-08-17T12:18:24Z",
    "updated": "2007-08-23T12:44:34Z",
    "abstract_stats": {
      "total_words": 100,
      "unique_words": 58,
      "total_sentences": 3,
      "avg_words_per_sentence": 33.333333333333336,
      "avg_word_length": 5.36
    }
  },
  {
    "arxiv_id": "0709.0509v1",
    "title": "Filtering Additive Measurement Noise with Maximum Entropy in the Mean",
    "authors": [
      "Henryk Gzyl",
      "Enrique ter Horst"
    ],
    "abstract": "The purpose of this note is to show how the method of maximum entropy in the\nmean (MEM) may be used to improve parametric estimation when the measurements\nare corrupted by large level of noise. The method is developed in the context\non a concrete example: that of estimation of the parameter in an exponential\ndistribution. We compare the performance of our method with the bayesian and\nmaximum likelihood approaches.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-09-04T19:36:22Z",
    "updated": "2007-09-04T19:36:22Z",
    "abstract_stats": {
      "total_words": 70,
      "unique_words": 49,
      "total_sentences": 3,
      "avg_words_per_sentence": 23.333333333333332,
      "avg_word_length": 4.885714285714286
    }
  },
  {
    "arxiv_id": "0710.0485v2",
    "title": "Prediction with expert advice for the Brier game",
    "authors": [
      "Vladimir Vovk",
      "Fedor Zhdanov"
    ],
    "abstract": "We show that the Brier game of prediction is mixable and find the optimal\nlearning rate and substitution function for it. The resulting prediction\nalgorithm is applied to predict results of football and tennis matches. The\ntheoretical performance guarantee turns out to be rather tight on these data\nsets, especially in the case of the more extensive tennis data.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-10-02T10:08:41Z",
    "updated": "2008-06-27T18:45:01Z",
    "abstract_stats": {
      "total_words": 59,
      "unique_words": 45,
      "total_sentences": 3,
      "avg_words_per_sentence": 19.666666666666668,
      "avg_word_length": 5.101694915254237
    }
  },
  {
    "arxiv_id": "0710.2848v1",
    "title": "Consistency of trace norm minimization",
    "authors": [
      "Francis Bach"
    ],
    "abstract": "Regularization by the sum of singular values, also referred to as the trace\nnorm, is a popular technique for estimating low rank rectangular matrices. In\nthis paper, we extend some of the consistency results of the Lasso to provide\nnecessary and sufficient conditions for rank consistency of trace norm\nminimization with the square loss. We also provide an adaptive version that is\nrank consistent even when the necessary condition for the non adaptive version\nis not fulfilled.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-10-15T15:38:33Z",
    "updated": "2007-10-15T15:38:33Z",
    "abstract_stats": {
      "total_words": 77,
      "unique_words": 52,
      "total_sentences": 3,
      "avg_words_per_sentence": 25.666666666666668,
      "avg_word_length": 5.142857142857143
    }
  },
  {
    "arxiv_id": "0711.3594v1",
    "title": "Clustering with Transitive Distance and K-Means Duality",
    "authors": [
      "Chunjing Xu",
      "Jianzhuang Liu",
      "Xiaoou Tang"
    ],
    "abstract": "Recent spectral clustering methods are a propular and powerful technique for\ndata clustering. These methods need to solve the eigenproblem whose\ncomputational complexity is $O(n^3)$, where $n$ is the number of data samples.\nIn this paper, a non-eigenproblem based clustering method is proposed to deal\nwith the clustering problem. Its performance is comparable to the spectral\nclustering algorithms but it is more efficient with computational complexity\n$O(n^2)$. We show that with a transitive distance and an observed property,\ncalled K-means duality, our algorithm can be used to handle data sets with\ncomplex cluster shapes, multi-scale clusters, and noise. Moreover, no\nparameters except the number of clusters need to be set in our algorithm.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-11-22T15:05:35Z",
    "updated": "2007-11-22T15:05:35Z",
    "abstract_stats": {
      "total_words": 120,
      "unique_words": 79,
      "total_sentences": 6,
      "avg_words_per_sentence": 20.0,
      "avg_word_length": 5.066666666666666
    }
  },
  {
    "arxiv_id": "0711.4452v1",
    "title": "Covariance and PCA for Categorical Variables",
    "authors": [
      "Hirotaka Niitsuma",
      "Takashi Okada"
    ],
    "abstract": "Covariances from categorical variables are defined using a regular simplex\nexpression for categories. The method follows the variance definition by Gini,\nand it gives the covariance as a solution of simultaneous equations. The\ncalculated results give reasonable values for test data. A method of principal\ncomponent analysis (RS-PCA) is also proposed using regular simplex expressions,\nwhich allows easy interpretation of the principal components. The proposed\nmethods apply to variable selection problem of categorical data USCensus1990\ndata. The proposed methods give appropriate criterion for the variable\nselection problem of categorical",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-11-28T12:05:47Z",
    "updated": "2007-11-28T12:05:47Z",
    "abstract_stats": {
      "total_words": 90,
      "unique_words": 59,
      "total_sentences": 6,
      "avg_words_per_sentence": 15.0,
      "avg_word_length": 6.033333333333333
    }
  },
  {
    "arxiv_id": "0712.0130v1",
    "title": "On the Relationship between the Posterior and Optimal Similarity",
    "authors": [
      "Thomas M. Breuel"
    ],
    "abstract": "For a classification problem described by the joint density $P(\\omega,x)$,\nmodels of $P(\\omega\\eq\\omega'|x,x')$ (the ``Bayesian similarity measure'') have\nbeen shown to be an optimal similarity measure for nearest neighbor\nclassification. This paper analyzes demonstrates several additional properties\nof that conditional distribution. The paper first shows that we can\nreconstruct, up to class labels, the class posterior distribution $P(\\omega|x)$\ngiven $P(\\omega\\eq\\omega'|x,x')$, gives a procedure for recovering the class\nlabels, and gives an asymptotically Bayes-optimal classification procedure. It\nalso shows, given such an optimal similarity measure, how to construct a\nclassifier that outperforms the nearest neighbor classifier and achieves\nBayes-optimal classification rates. The paper then analyzes Bayesian similarity\nin a framework where a classifier faces a number of related classification\ntasks (multitask learning) and illustrates that reconstruction of the class\nposterior distribution is not possible in general. Finally, the paper\nidentifies a distinct class of classification problems using\n$P(\\omega\\eq\\omega'|x,x')$ and shows that using $P(\\omega\\eq\\omega'|x,x')$ to\nsolve those problems is the Bayes optimal solution.",
    "categories": [
      "cs.LG",
      "I.5.3; I.5.2"
    ],
    "published": "2007-12-02T09:38:26Z",
    "updated": "2007-12-02T09:38:26Z",
    "abstract_stats": {
      "total_words": 187,
      "unique_words": 86,
      "total_sentences": 6,
      "avg_words_per_sentence": 31.166666666666668,
      "avg_word_length": 5.363636363636363
    }
  },
  {
    "arxiv_id": "0712.0653v2",
    "title": "Equations of States in Singular Statistical Estimation",
    "authors": [
      "Sumio Watanabe"
    ],
    "abstract": "Learning machines which have hierarchical structures or hidden variables are\nsingular statistical models because they are nonidentifiable and their Fisher\ninformation matrices are singular. In singular statistical models, neither the\nBayes a posteriori distribution converges to the normal distribution nor the\nmaximum likelihood estimator satisfies asymptotic normality. This is the main\nreason why it has been difficult to predict their generalization performances\nfrom trained states. In this paper, we study four errors, (1) Bayes\ngeneralization error, (2) Bayes training error, (3) Gibbs generalization error,\nand (4) Gibbs training error, and prove that there are mathematical relations\namong these errors. The formulas proved in this paper are equations of states\nin statistical estimation because they hold for any true distribution, any\nparametric model, and any a priori distribution. Also we show that Bayes and\nGibbs generalization errors are estimated by Bayes and Gibbs training errors,\nand propose widely applicable information criteria which can be applied to both\nregular and singular statistical models.",
    "categories": [
      "cs.LG",
      "I.2.6"
    ],
    "published": "2007-12-05T05:39:07Z",
    "updated": "2009-05-11T05:49:09Z",
    "abstract_stats": {
      "total_words": 161,
      "unique_words": 97,
      "total_sentences": 6,
      "avg_words_per_sentence": 26.833333333333332,
      "avg_word_length": 5.819875776397516
    }
  },
  {
    "arxiv_id": "0712.2869v1",
    "title": "Density estimation in linear time",
    "authors": [
      "Satyaki Mahalanabis",
      "Daniel Stefankovic"
    ],
    "abstract": "We consider the problem of choosing a density estimate from a set of\ndistributions F, minimizing the L1-distance to an unknown distribution\n(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the\nproblem: Scheffe tournament winner and minimum distance estimate. The Scheffe\ntournament estimate requires fewer computations than the minimum distance\nestimate, but has strictly weaker guarantees than the latter.\n  We focus on the computational aspect of density estimation. We present two\nalgorithms, both with the same guarantee as the minimum distance estimate. The\nfirst one, a modification of the minimum distance estimate, uses the same\nnumber (quadratic in |F|) of computations as the Scheffe tournament. The second\none, called ``efficient minimum loss-weight estimate,'' uses only a linear\nnumber of computations, assuming that F is preprocessed.\n  We also give examples showing that the guarantees of the algorithms cannot be\nimproved and explore randomized algorithms for density estimation.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-12-18T03:30:05Z",
    "updated": "2007-12-18T03:30:05Z",
    "abstract_stats": {
      "total_words": 150,
      "unique_words": 80,
      "total_sentences": 8,
      "avg_words_per_sentence": 18.75,
      "avg_word_length": 5.566666666666666
    }
  },
  {
    "arxiv_id": "0712.3402v1",
    "title": "Graph kernels between point clouds",
    "authors": [
      "Francis Bach"
    ],
    "abstract": "Point clouds are sets of points in two or three dimensions. Most kernel\nmethods for learning on sets of points have not yet dealt with the specific\ngeometrical invariances and practical constraints associated with point clouds\nin computer vision and graphics. In this paper, we present extensions of graph\nkernels for point clouds, which allow to use kernel methods for such ob jects\nas shapes, line drawings, or any three-dimensional point clouds. In order to\ndesign rich and numerically efficient kernels with as few free parameters as\npossible, we use kernels between covariance matrices and their factorizations\non graphical models. We derive polynomial time dynamic programming recursions\nand present applications to recognition of handwritten digits and Chinese\ncharacters from few training examples.",
    "categories": [
      "cs.LG"
    ],
    "published": "2007-12-20T13:06:50Z",
    "updated": "2007-12-20T13:06:50Z",
    "abstract_stats": {
      "total_words": 123,
      "unique_words": 84,
      "total_sentences": 5,
      "avg_words_per_sentence": 24.6,
      "avg_word_length": 5.479674796747967
    }
  },
  {
    "arxiv_id": "0801.1988v1",
    "title": "Online variants of the cross-entropy method",
    "authors": [
      "Istvan Szita",
      "Andras Lorincz"
    ],
    "abstract": "The cross-entropy method is a simple but efficient method for global\noptimization. In this paper we provide two online variants of the basic CEM,\ntogether with a proof of convergence.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-01-14T06:56:42Z",
    "updated": "2008-01-14T06:56:42Z",
    "abstract_stats": {
      "total_words": 31,
      "unique_words": 27,
      "total_sentences": 2,
      "avg_words_per_sentence": 15.5,
      "avg_word_length": 4.838709677419355
    }
  },
  {
    "arxiv_id": "0801.4061v1",
    "title": "The optimal assignment kernel is not positive definite",
    "authors": [
      "Jean-Philippe Vert"
    ],
    "abstract": "We prove that the optimal assignment kernel, proposed recently as an attempt\nto embed labeled graphs and more generally tuples of basic data to a Hilbert\nspace, is in fact not always positive definite.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-01-26T07:32:48Z",
    "updated": "2008-01-26T07:32:48Z",
    "abstract_stats": {
      "total_words": 34,
      "unique_words": 33,
      "total_sentences": 1,
      "avg_words_per_sentence": 34.0,
      "avg_word_length": 4.852941176470588
    }
  },
  {
    "arxiv_id": "0802.1002v1",
    "title": "New Estimation Procedures for PLS Path Modelling",
    "authors": [
      "Xavier Bry"
    ],
    "abstract": "Given R groups of numerical variables X1, ... XR, we assume that each group\nis the result of one underlying latent variable, and that all latent variables\nare bound together through a linear equation system. Moreover, we assume that\nsome explanatory latent variables may interact pairwise in one or more\nequations. We basically consider PLS Path Modelling's algorithm to estimate\nboth latent variables and the model's coefficients. New \"external\" estimation\nschemes are proposed that draw latent variables towards strong group structures\nin a more flexible way. New \"internal\" estimation schemes are proposed to\nenable PLSPM to make good use of variable group complementarity and to deal\nwith interactions. Application examples are given.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-02-07T15:18:27Z",
    "updated": "2008-02-07T15:18:27Z",
    "abstract_stats": {
      "total_words": 113,
      "unique_words": 75,
      "total_sentences": 7,
      "avg_words_per_sentence": 16.142857142857142,
      "avg_word_length": 5.380530973451328
    }
  },
  {
    "arxiv_id": "0802.1430v2",
    "title": "A New Approach to Collaborative Filtering: Operator Estimation with\n  Spectral Regularization",
    "authors": [
      "Jacob Abernethy",
      "Francis Bach",
      "Theodoros Evgeniou",
      "Jean-Philippe Vert"
    ],
    "abstract": "We present a general approach for collaborative filtering (CF) using spectral\nregularization to learn linear operators from \"users\" to the \"objects\" they\nrate. Recent low-rank type matrix completion approaches to CF are shown to be\nspecial cases. However, unlike existing regularization based CF methods, our\napproach can be used to also incorporate information such as attributes of the\nusers or the objects -- a limitation of existing regularization based CF\nmethods. We then provide novel representer theorems that we use to develop new\nestimation methods. We provide learning algorithms based on low-rank\ndecompositions, and test them on a standard CF dataset. The experiments\nindicate the advantages of generalizing the existing regularization based CF\nmethods to incorporate related information about users and objects. Finally, we\nshow that certain multi-task learning methods can be also seen as special cases\nof our proposed approach.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-02-11T12:55:34Z",
    "updated": "2008-12-19T14:05:14Z",
    "abstract_stats": {
      "total_words": 143,
      "unique_words": 83,
      "total_sentences": 7,
      "avg_words_per_sentence": 20.428571428571427,
      "avg_word_length": 5.461538461538462
    }
  },
  {
    "arxiv_id": "0807.0093v1",
    "title": "Graph Kernels",
    "authors": [
      "S. V. N. Vishwanathan",
      "Karsten M. Borgwardt",
      "Imre Risi Kondor",
      "Nicol N. Schraudolph"
    ],
    "abstract": "We present a unified framework to study graph kernels, special cases of which\ninclude the random walk graph kernel \\citep{GaeFlaWro03,BorOngSchVisetal05},\nmarginalized graph kernel \\citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},\nand geometric kernel on graphs \\citep{Gaertner02}. Through extensions of linear\nalgebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a\nSylvester equation, we construct an algorithm that improves the time complexity\nof kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,\nconjugate gradient solvers or fixed-point iterations bring our algorithm into\nthe sub-cubic domain. Experiments on graphs from bioinformatics and other\napplication domains show that it is often more than a thousand times faster\nthan previous approaches. We then explore connections between diffusion kernels\n\\citep{KonLaf02}, regularization on graphs \\citep{SmoKon03}, and graph kernels,\nand use these connections to propose new graph kernels. Finally, we show that\nrational kernels \\citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized\nto graphs reduce to the random walk graph kernel.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-07-01T09:46:14Z",
    "updated": "2008-07-01T09:46:14Z",
    "abstract_stats": {
      "total_words": 163,
      "unique_words": 105,
      "total_sentences": 6,
      "avg_words_per_sentence": 27.166666666666668,
      "avg_word_length": 5.748466257668712
    }
  },
  {
    "arxiv_id": "0807.2983v1",
    "title": "On Probability Distributions for Trees: Representations, Inference and\n  Learning",
    "authors": [
      "François Denis",
      "Amaury Habrard",
      "Rémi Gilleron",
      "Marc Tommasi",
      "Édouard Gilbert"
    ],
    "abstract": "We study probability distributions over free algebras of trees. Probability\ndistributions can be seen as particular (formal power) tree series [Berstel et\nal 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely\nstudied class of tree series is the class of rational (or recognizable) tree\nseries which can be defined either in an algebraic way or by means of\nmultiplicity tree automata. We argue that the algebraic representation is very\nconvenient to model probability distributions over a free algebra of trees.\nFirst, as in the string case, the algebraic representation allows to design\nlearning algorithms for the whole class of probability distributions defined by\nrational tree series. Note that learning algorithms for rational tree series\ncorrespond to learning algorithms for weighted tree automata where both the\nstructure and the weights are learned. Second, the algebraic representation can\nbe easily extended to deal with unranked trees (like XML trees where a symbol\nmay have an unbounded number of children). Both properties are particularly\nrelevant for applications: nondeterministic automata are required for the\ninference problem to be relevant (recall that Hidden Markov Models are\nequivalent to nondeterministic string automata); nowadays applications for Web\nInformation Extraction, Web Services and document processing consider unranked\ntrees.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-07-18T14:41:44Z",
    "updated": "2008-07-18T14:41:44Z",
    "abstract_stats": {
      "total_words": 208,
      "unique_words": 112,
      "total_sentences": 10,
      "avg_words_per_sentence": 20.8,
      "avg_word_length": 5.524038461538462
    }
  },
  {
    "arxiv_id": "0807.4198v2",
    "title": "Positive factor networks: A graphical framework for modeling\n  non-negative sequential data",
    "authors": [
      "Brian K. Vogel"
    ],
    "abstract": "We present a novel graphical framework for modeling non-negative sequential\ndata with hierarchical structure. Our model corresponds to a network of coupled\nnon-negative matrix factorization (NMF) modules, which we refer to as a\npositive factor network (PFN). The data model is linear, subject to\nnon-negativity constraints, so that observation data consisting of an additive\ncombination of individually representable observations is also representable by\nthe network. This is a desirable property for modeling problems in\ncomputational auditory scene analysis, since distinct sound sources in the\nenvironment are often well-modeled as combining additively in the corresponding\nmagnitude spectrogram. We propose inference and learning algorithms that\nleverage existing NMF algorithms and that are straightforward to implement. We\npresent a target tracking example and provide results for synthetic observation\ndata which serve to illustrate the interesting properties of PFNs and motivate\ntheir potential usefulness in applications such as music transcription, source\nseparation, and speech recognition. We show how a target process characterized\nby a hierarchical state transition model can be represented as a PFN. Our\nresults illustrate that a PFN which is defined in terms of a single target\nobservation can then be used to effectively track the states of multiple\nsimultaneous targets. Our results show that the quality of the inferred target\nstates degrades gradually as the observation noise is increased. We also\npresent results for an example in which meaningful hierarchical features are\nextracted from a spectrogram. Such a hierarchical representation could be\nuseful for music transcription and source separation applications. We also\npropose a network for language modeling.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-07-25T22:50:46Z",
    "updated": "2009-07-16T00:30:26Z",
    "abstract_stats": {
      "total_words": 261,
      "unique_words": 139,
      "total_sentences": 12,
      "avg_words_per_sentence": 21.75,
      "avg_word_length": 5.762452107279693
    }
  },
  {
    "arxiv_id": "0811.0139v1",
    "title": "Entropy, Perception, and Relativity",
    "authors": [
      "Stefan Jaeger"
    ],
    "abstract": "In this paper, I expand Shannon's definition of entropy into a new form of\nentropy that allows integration of information from different random events.\nShannon's notion of entropy is a special case of my more general definition of\nentropy. I define probability using a so-called performance function, which is\nde facto an exponential distribution. Assuming that my general notion of\nentropy reflects the true uncertainty about a probabilistic event, I understand\nthat our perceived uncertainty differs. I claim that our perception is the\nresult of two opposing forces similar to the two famous antagonists in Chinese\nphilosophy: Yin and Yang. Based on this idea, I show that our perceived\nuncertainty matches the true uncertainty in points determined by the golden\nratio. I demonstrate that the well-known sigmoid function, which we typically\nemploy in artificial neural networks as a non-linear threshold function,\ndescribes the actual performance. Furthermore, I provide a motivation for the\ntime dilation in Einstein's Special Relativity, basically claiming that\nalthough time dilation conforms with our perception, it does not correspond to\nreality. At the end of the paper, I show how to apply this theoretical\nframework to practical applications. I present recognition rates for a pattern\nrecognition problem, and also propose a network architecture that can take\nadvantage of general entropy to solve complex decision problems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-11-02T08:02:43Z",
    "updated": "2008-11-02T08:02:43Z",
    "abstract_stats": {
      "total_words": 224,
      "unique_words": 137,
      "total_sentences": 10,
      "avg_words_per_sentence": 22.4,
      "avg_word_length": 5.308035714285714
    }
  },
  {
    "arxiv_id": "0811.1629v1",
    "title": "Stability Bound for Stationary Phi-mixing and Beta-mixing Processes",
    "authors": [
      "Mehryar Mohri",
      "Afshin Rostamizadeh"
    ],
    "abstract": "Most generalization bounds in learning theory are based on some measure of\nthe complexity of the hypothesis class used, independently of any algorithm. In\ncontrast, the notion of algorithmic stability can be used to derive tight\ngeneralization bounds that are tailored to specific learning algorithms by\nexploiting their particular properties. However, as in much of learning theory,\nexisting stability analyses and bounds apply only in the scenario where the\nsamples are independently and identically distributed. In many machine learning\napplications, however, this assumption does not hold. The observations received\nby the learning algorithm often have some inherent temporal dependence.\n  This paper studies the scenario where the observations are drawn from a\nstationary phi-mixing or beta-mixing sequence, a widely adopted assumption in\nthe study of non-i.i.d. processes that implies a dependence between\nobservations weakening over time. We prove novel and distinct stability-based\ngeneralization bounds for stationary phi-mixing and beta-mixing sequences.\nThese bounds strictly generalize the bounds given in the i.i.d. case and apply\nto all stable learning algorithms, thereby extending the use of\nstability-bounds to non-i.i.d. scenarios.\n  We also illustrate the application of our phi-mixing generalization bounds to\ngeneral classes of learning algorithms, including Support Vector Regression,\nKernel Ridge Regression, and Support Vector Machines, and many other kernel\nregularization-based and relative entropy-based regularization algorithms.\nThese novel bounds can thus be viewed as the first theoretical basis for the\nuse of these algorithms in non-i.i.d. scenarios.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-11-11T05:09:08Z",
    "updated": "2008-11-11T05:09:08Z",
    "abstract_stats": {
      "total_words": 254,
      "unique_words": 128,
      "total_sentences": 22,
      "avg_words_per_sentence": 11.545454545454545,
      "avg_word_length": 5.511811023622047
    }
  },
  {
    "arxiv_id": "0811.2016v1",
    "title": "Land Cover Mapping Using Ensemble Feature Selection Methods",
    "authors": [
      "A. Gidudu",
      "B. Abe",
      "T. Marwala"
    ],
    "abstract": "Ensemble classification is an emerging approach to land cover mapping whereby\nthe final classification output is a result of a consensus of classifiers.\nIntuitively, an ensemble system should consist of base classifiers which are\ndiverse i.e. classifiers whose decision boundaries err differently. In this\npaper ensemble feature selection is used to impose diversity in ensembles. The\nfeatures of the constituent base classifiers for each ensemble were created\nthrough an exhaustive search algorithm using different separability indices.\nFor each ensemble, the classification accuracy was derived as well as a\ndiversity measure purported to give a measure of the inensemble diversity. The\ncorrelation between ensemble classification accuracy and diversity measure was\ndetermined to establish the interplay between the two variables. From the\nfindings of this paper, diversity measures as currently formulated do not\nprovide an adequate means upon which to constitute ensembles for land cover\nmapping.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-11-13T01:23:47Z",
    "updated": "2008-11-13T01:23:47Z",
    "abstract_stats": {
      "total_words": 145,
      "unique_words": 86,
      "total_sentences": 9,
      "avg_words_per_sentence": 16.11111111111111,
      "avg_word_length": 5.827586206896552
    }
  },
  {
    "arxiv_id": "0812.1357v1",
    "title": "A Novel Clustering Algorithm Based on Quantum Random Walk",
    "authors": [
      "Qiang Li",
      "Yan He",
      "Jing-ping Jiang"
    ],
    "abstract": "The enormous successes have been made by quantum algorithms during the last\ndecade. In this paper, we combine the quantum random walk (QRW) with the\nproblem of data clustering, and develop two clustering algorithms based on the\none dimensional QRW. Then, the probability distributions on the positions\ninduced by QRW in these algorithms are investigated, which also indicates the\npossibility of obtaining better results. Consequently, the experimental results\nhave demonstrated that data points in datasets are clustered reasonably and\nefficiently, and the clustering algorithms are of fast rates of convergence.\nMoreover, the comparison with other algorithms also provides an indication of\nthe effectiveness of the proposed approach.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-12-07T15:22:27Z",
    "updated": "2008-12-07T15:22:27Z",
    "abstract_stats": {
      "total_words": 107,
      "unique_words": 68,
      "total_sentences": 5,
      "avg_words_per_sentence": 21.4,
      "avg_word_length": 5.738317757009346
    }
  },
  {
    "arxiv_id": "0812.1869v1",
    "title": "Convex Sparse Matrix Factorizations",
    "authors": [
      "Francis Bach",
      "Julien Mairal",
      "Jean Ponce"
    ],
    "abstract": "We present a convex formulation of dictionary learning for sparse signal\ndecomposition. Convexity is obtained by replacing the usual explicit upper\nbound on the dictionary size by a convex rank-reducing term similar to the\ntrace norm. In particular, our formulation introduces an explicit trade-off\nbetween size and sparsity of the decomposition of rectangular matrices. Using a\nlarge set of synthetic examples, we compare the estimation abilities of the\nconvex and non-convex approaches, showing that while the convex formulation has\na single local minimum, this may lead in some cases to performance which is\ninferior to the local minima of the non-convex formulation.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-12-10T09:00:40Z",
    "updated": "2008-12-10T09:00:40Z",
    "abstract_stats": {
      "total_words": 106,
      "unique_words": 69,
      "total_sentences": 4,
      "avg_words_per_sentence": 26.5,
      "avg_word_length": 5.254716981132075
    }
  },
  {
    "arxiv_id": "0812.3145v2",
    "title": "Binary Classification Based on Potentials",
    "authors": [
      "Erik Boczko",
      "Andrew DiLullo",
      "Todd Young"
    ],
    "abstract": "We introduce a simple and computationally trivial method for binary\nclassification based on the evaluation of potential functions. We demonstrate\nthat despite the conceptual and computational simplicity of the method its\nperformance can match or exceed that of standard Support Vector Machine\nmethods.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-12-16T20:41:06Z",
    "updated": "2008-12-16T21:05:28Z",
    "abstract_stats": {
      "total_words": 43,
      "unique_words": 35,
      "total_sentences": 2,
      "avg_words_per_sentence": 21.5,
      "avg_word_length": 5.976744186046512
    }
  },
  {
    "arxiv_id": "0812.3465v2",
    "title": "Linearly Parameterized Bandits",
    "authors": [
      "Paat Rusmevichientong",
      "John N. Tsitsiklis"
    ],
    "abstract": "We consider bandit problems involving a large (possibly infinite) collection\nof arms, in which the expected reward of each arm is a linear function of an\n$r$-dimensional random vector $\\mathbf{Z} \\in \\mathbb{R}^r$, where $r \\geq 2$.\nThe objective is to minimize the cumulative regret and Bayes risk. When the set\nof arms corresponds to the unit sphere, we prove that the regret and Bayes risk\nis of order $\\Theta(r \\sqrt{T})$, by establishing a lower bound for an\narbitrary policy, and showing that a matching upper bound is obtained through a\npolicy that alternates between exploration and exploitation phases. The\nphase-based policy is also shown to be effective if the set of arms satisfies a\nstrong convexity condition. For the case of a general set of arms, we describe\na near-optimal policy whose regret and Bayes risk admit upper bounds of the\nform $O(r \\sqrt{T} \\log^{3/2} T)$.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-12-18T07:59:33Z",
    "updated": "2010-02-24T15:54:49Z",
    "abstract_stats": {
      "total_words": 158,
      "unique_words": 92,
      "total_sentences": 5,
      "avg_words_per_sentence": 31.6,
      "avg_word_length": 4.360759493670886
    }
  },
  {
    "arxiv_id": "0812.4952v4",
    "title": "Importance Weighted Active Learning",
    "authors": [
      "Alina Beygelzimer",
      "Sanjoy Dasgupta",
      "John Langford"
    ],
    "abstract": "We present a practical and statistically consistent scheme for actively\nlearning binary classifiers under general loss functions. Our algorithm uses\nimportance weighting to correct sampling bias, and by controlling the variance,\nwe are able to give rigorous label complexity bounds for the learning process.\nExperiments on passively labeled data show that this approach reduces the label\ncomplexity required to achieve good predictive performance on many learning\nproblems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2008-12-29T18:29:08Z",
    "updated": "2009-05-20T17:40:23Z",
    "abstract_stats": {
      "total_words": 67,
      "unique_words": 55,
      "total_sentences": 3,
      "avg_words_per_sentence": 22.333333333333332,
      "avg_word_length": 6.0
    }
  },
  {
    "arxiv_id": "0902.1258v1",
    "title": "Extraction de concepts sous contraintes dans des données d'expression\n  de gènes",
    "authors": [
      "Baptiste Jeudy",
      "François Rioult"
    ],
    "abstract": "In this paper, we propose a technique to extract constrained formal concepts.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-07T18:01:09Z",
    "updated": "2009-02-07T18:01:09Z",
    "abstract_stats": {
      "total_words": 12,
      "unique_words": 12,
      "total_sentences": 1,
      "avg_words_per_sentence": 12.0,
      "avg_word_length": 5.333333333333333
    }
  },
  {
    "arxiv_id": "0902.1259v1",
    "title": "Database Transposition for Constrained (Closed) Pattern Mining",
    "authors": [
      "Baptiste Jeudy",
      "François Rioult"
    ],
    "abstract": "Recently, different works proposed a new way to mine patterns in databases\nwith pathological size. For example, experiments in genome biology usually\nprovide databases with thousands of attributes (genes) but only tens of objects\n(experiments). In this case, mining the \"transposed\" database runs through a\nsmaller search space, and the Galois connection allows to infer the closed\npatterns of the original database. We focus here on constrained pattern mining\nfor those unusual databases and give a theoretical framework for database and\nconstraint transposition. We discuss the properties of constraint transposition\nand look into classical constraints. We then address the problem of generating\nthe closed patterns of the original database satisfying the constraint,\nstarting from those mined in the \"transposed\" database. Finally, we show how to\ngenerate all the patterns satisfying the constraint from the closed ones.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-07T18:01:56Z",
    "updated": "2009-02-07T18:01:56Z",
    "abstract_stats": {
      "total_words": 136,
      "unique_words": 81,
      "total_sentences": 7,
      "avg_words_per_sentence": 19.428571428571427,
      "avg_word_length": 5.639705882352941
    }
  },
  {
    "arxiv_id": "0902.1284v2",
    "title": "Multi-Label Prediction via Compressed Sensing",
    "authors": [
      "Daniel Hsu",
      "Sham M. Kakade",
      "John Langford",
      "Tong Zhang"
    ],
    "abstract": "We consider multi-label prediction problems with large output spaces under\nthe assumption of output sparsity -- that the target (label) vectors have small\nsupport. We develop a general theory for a variant of the popular error\ncorrecting output code scheme, using ideas from compressed sensing for\nexploiting this sparsity. The method can be regarded as a simple reduction from\nmulti-label regression problems to binary regression problems. We show that the\nnumber of subproblems need only be logarithmic in the total number of possible\nlabels, making this approach radically more efficient than others. We also\nstate and prove robustness guarantees for this method in the form of regret\ntransform bounds (in general), and also provide a more detailed analysis for\nthe linear prediction setting.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-08T02:30:06Z",
    "updated": "2009-06-02T16:23:28Z",
    "abstract_stats": {
      "total_words": 124,
      "unique_words": 81,
      "total_sentences": 5,
      "avg_words_per_sentence": 24.8,
      "avg_word_length": 5.298387096774194
    }
  },
  {
    "arxiv_id": "0902.3373v1",
    "title": "Learning rules from multisource data for cardiac monitoring",
    "authors": [
      "Marie-Odile Cordier",
      "Elisa Fromont",
      "René Quiniou"
    ],
    "abstract": "This paper formalises the concept of learning symbolic rules from multisource\ndata in a cardiac monitoring context. Our sources, electrocardiograms and\narterial blood pressure measures, describe cardiac behaviours from different\nviewpoints. To learn interpretable rules, we use an Inductive Logic Programming\n(ILP) method. We develop an original strategy to cope with the dimensionality\nissues caused by using this ILP technique on a rich multisource language. The\nresults show that our method greatly improves the feasibility and the\nefficiency of the process while staying accurate. They also confirm the\nbenefits of using multiple sources to improve the diagnosis of cardiac\narrhythmias.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-19T13:47:53Z",
    "updated": "2009-02-19T13:47:53Z",
    "abstract_stats": {
      "total_words": 100,
      "unique_words": 73,
      "total_sentences": 6,
      "avg_words_per_sentence": 16.666666666666668,
      "avg_word_length": 5.8
    }
  },
  {
    "arxiv_id": "0902.3846v1",
    "title": "Uniqueness of Low-Rank Matrix Completion by Rigidity Theory",
    "authors": [
      "Amit Singer",
      "Mihai Cucuringu"
    ],
    "abstract": "The problem of completing a low-rank matrix from a subset of its entries is\noften encountered in the analysis of incomplete data sets exhibiting an\nunderlying factor model with applications in collaborative filtering, computer\nvision and control. Most recent work had been focused on constructing efficient\nalgorithms for exact or approximate recovery of the missing matrix entries and\nproving lower bounds for the number of known entries that guarantee a\nsuccessful recovery with high probability. A related problem from both the\nmathematical and algorithmic point of view is the distance geometry problem of\nrealizing points in a Euclidean space from a given subset of their pairwise\ndistances. Rigidity theory answers basic questions regarding the uniqueness of\nthe realization satisfying a given partial set of distances. We observe that\nbasic ideas and tools of rigidity theory can be adapted to determine uniqueness\nof low-rank matrix completion, where inner products play the role that\ndistances play in rigidity theory. This observation leads to an efficient\nrandomized algorithm for testing both local and global unique completion.\nCrucial to our analysis is a new matrix, which we call the completion matrix,\nthat serves as the analogue of the rigidity matrix.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-23T04:05:48Z",
    "updated": "2009-02-23T04:05:48Z",
    "abstract_stats": {
      "total_words": 198,
      "unique_words": 118,
      "total_sentences": 7,
      "avg_words_per_sentence": 28.285714285714285,
      "avg_word_length": 5.363636363636363
    }
  },
  {
    "arxiv_id": "0902.4127v2",
    "title": "Prediction with expert evaluators' advice",
    "authors": [
      "Alexey Chernov",
      "Vladimir Vovk"
    ],
    "abstract": "We introduce a new protocol for prediction with expert advice in which each\nexpert evaluates the learner's and his own performance using a loss function\nthat may change over time and may be different from the loss functions used by\nthe other experts. The learner's goal is to perform better or not much worse\nthan each expert, as evaluated by that expert, for all experts simultaneously.\nIf the loss functions used by the experts are all proper scoring rules and all\nmixable, we show that the defensive forecasting algorithm enjoys the same\nperformance guarantee as that attainable by the Aggregating Algorithm in the\nstandard setting and known to be optimal. This result is also applied to the\ncase of \"specialist\" (or \"sleeping\") experts. In this case, the defensive\nforecasting algorithm reduces to a simple modification of the Aggregating\nAlgorithm.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-24T11:47:03Z",
    "updated": "2009-03-23T16:28:41Z",
    "abstract_stats": {
      "total_words": 141,
      "unique_words": 81,
      "total_sentences": 5,
      "avg_words_per_sentence": 28.2,
      "avg_word_length": 4.950354609929078
    }
  },
  {
    "arxiv_id": "0902.4228v1",
    "title": "Multiplicative updates For Non-Negative Kernel SVM",
    "authors": [
      "Vamsi K. Potluru",
      "Sergey M. Plis",
      "Morten Morup",
      "Vince D. Calhoun",
      "Terran Lane"
    ],
    "abstract": "We present multiplicative updates for solving hard and soft margin support\nvector machines (SVM) with non-negative kernels. They follow as a natural\nextension of the updates for non-negative matrix factorization. No additional\nparam- eter setting, such as choosing learning, rate is required. Ex- periments\ndemonstrate rapid convergence to good classifiers. We analyze the rates of\nasymptotic convergence of the up- dates and establish tight bounds. We test the\nperformance on several datasets using various non-negative kernels and report\nequivalent generalization errors to that of a standard SVM.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-02-24T20:38:32Z",
    "updated": "2009-02-24T20:38:32Z",
    "abstract_stats": {
      "total_words": 90,
      "unique_words": 68,
      "total_sentences": 6,
      "avg_words_per_sentence": 15.0,
      "avg_word_length": 5.522222222222222
    }
  },
  {
    "arxiv_id": "0903.1125v1",
    "title": "Efficient Human Computation",
    "authors": [
      "Ran Gilad-Bachrach",
      "Aharon Bar-Hillel",
      "Liat Ein-Dor"
    ],
    "abstract": "Collecting large labeled data sets is a laborious and expensive task, whose\nscaling up requires division of the labeling workload between many teachers.\nWhen the number of classes is large, miscorrespondences between the labels\ngiven by the different teachers are likely to occur, which, in the extreme\ncase, may reach total inconsistency. In this paper we describe how globally\nconsistent labels can be obtained, despite the absence of teacher coordination,\nand discuss the possible efficiency of this process in terms of human labor. We\ndefine a notion of label efficiency, measuring the ratio between the number of\nglobally consistent labels obtained and the number of labels provided by\ndistributed teachers. We show that the efficiency depends critically on the\nratio alpha between the number of data instances seen by a single teacher, and\nthe number of classes. We suggest several algorithms for the distributed\nlabeling problem, and analyze their efficiency as a function of alpha. In\naddition, we provide an upper bound on label efficiency for the case of\ncompletely uncoordinated teachers, and show that efficiency approaches 0 as the\nratio between the number of labels each teacher provides and the number of\nclasses drops (i.e. alpha goes to 0).",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-03-05T22:39:46Z",
    "updated": "2009-03-05T22:39:46Z",
    "abstract_stats": {
      "total_words": 201,
      "unique_words": 104,
      "total_sentences": 9,
      "avg_words_per_sentence": 22.333333333333332,
      "avg_word_length": 5.149253731343284
    }
  },
  {
    "arxiv_id": "0903.2299v3",
    "title": "Differential Contrastive Divergence",
    "authors": [
      "David McAllester"
    ],
    "abstract": "This paper has been retracted.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-03-13T13:47:03Z",
    "updated": "2013-07-08T15:17:20Z",
    "abstract_stats": {
      "total_words": 5,
      "unique_words": 5,
      "total_sentences": 1,
      "avg_words_per_sentence": 5.0,
      "avg_word_length": 5.0
    }
  },
  {
    "arxiv_id": "0903.2870v2",
    "title": "On $p$-adic Classification",
    "authors": [
      "Patrick Erik Bradley"
    ],
    "abstract": "A $p$-adic modification of the split-LBG classification method is presented\nin which first clusterings and then cluster centers are computed which locally\nminimise an energy function. The outcome for a fixed dataset is independent of\nthe prime number $p$ with finitely many exceptions. The methods are applied to\nthe construction of $p$-adic classifiers in the context of learning.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-03-16T22:52:06Z",
    "updated": "2009-06-24T14:10:45Z",
    "abstract_stats": {
      "total_words": 61,
      "unique_words": 45,
      "total_sentences": 3,
      "avg_words_per_sentence": 20.333333333333332,
      "avg_word_length": 5.114754098360656
    }
  },
  {
    "arxiv_id": "0904.0814v1",
    "title": "Stability Analysis and Learning Bounds for Transductive Regression\n  Algorithms",
    "authors": [
      "Corinna Cortes",
      "Mehryar Mohri",
      "Dmitry Pechyony",
      "Ashish Rastogi"
    ],
    "abstract": "This paper uses the notion of algorithmic stability to derive novel\ngeneralization bounds for several families of transductive regression\nalgorithms, both by using convexity and closed-form solutions. Our analysis\nhelps compare the stability of these algorithms. It also shows that a number of\nwidely used transductive regression algorithms are in fact unstable. Finally,\nit reports the results of experiments with local transductive regression\ndemonstrating the benefit of our stability bounds for model selection, for one\nof the algorithms, in particular for determining the radius of the local\nneighborhood used by the algorithm.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-04-05T20:08:44Z",
    "updated": "2009-04-05T20:08:44Z",
    "abstract_stats": {
      "total_words": 93,
      "unique_words": 60,
      "total_sentences": 4,
      "avg_words_per_sentence": 23.25,
      "avg_word_length": 5.720430107526882
    }
  },
  {
    "arxiv_id": "0904.2160v1",
    "title": "Inferring Dynamic Bayesian Networks using Frequent Episode Mining",
    "authors": [
      "Debprakash Patnaik",
      "Srivatsan Laxman",
      "Naren Ramakrishnan"
    ],
    "abstract": "Motivation: Several different threads of research have been proposed for\nmodeling and mining temporal data. On the one hand, approaches such as dynamic\nBayesian networks (DBNs) provide a formal probabilistic basis to model\nrelationships between time-indexed random variables but these models are\nintractable to learn in the general case. On the other, algorithms such as\nfrequent episode mining are scalable to large datasets but do not exhibit the\nrigorous probabilistic interpretations that are the mainstay of the graphical\nmodels literature.\n  Results: We present a unification of these two seemingly diverse threads of\nresearch, by demonstrating how dynamic (discrete) Bayesian networks can be\ninferred from the results of frequent episode mining. This helps bridge the\nmodeling emphasis of the former with the counting emphasis of the latter.\nFirst, we show how, under reasonable assumptions on data characteristics and on\ninfluences of random variables, the optimal DBN structure can be computed using\na greedy, local, algorithm. Next, we connect the optimality of the DBN\nstructure with the notion of fixed-delay episodes and their counts of distinct\noccurrences. Finally, to demonstrate the practical feasibility of our approach,\nwe focus on a specific (but broadly applicable) class of networks, called\nexcitatory networks, and show how the search for the optimal DBN structure can\nbe conducted using just information from frequent episodes. Application on\ndatasets gathered from mathematical models of spiking neurons as well as real\nneuroscience datasets are presented.\n  Availability: Algorithmic implementations, simulator codebases, and datasets\nare available from our website at http://neural-code.cs.vt.edu/dbn",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-04-14T17:32:00Z",
    "updated": "2009-04-14T17:32:00Z",
    "abstract_stats": {
      "total_words": 257,
      "unique_words": 153,
      "total_sentences": 13,
      "avg_words_per_sentence": 19.76923076923077,
      "avg_word_length": 5.571984435797665
    }
  },
  {
    "arxiv_id": "0904.3664v1",
    "title": "Introduction to Machine Learning: Class Notes 67577",
    "authors": [
      "Amnon Shashua"
    ],
    "abstract": "Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-04-23T11:40:57Z",
    "updated": "2009-04-23T11:40:57Z",
    "abstract_stats": {
      "total_words": 31,
      "unique_words": 29,
      "total_sentences": 1,
      "avg_words_per_sentence": 31.0,
      "avg_word_length": 5.967741935483871
    }
  },
  {
    "arxiv_id": "0904.4527v1",
    "title": "Limits of Learning about a Categorical Latent Variable under Prior\n  Near-Ignorance",
    "authors": [
      "Alberto Piatti",
      "Marco Zaffalon",
      "Fabio Trojani",
      "Marcus Hutter"
    ],
    "abstract": "In this paper, we consider the coherent theory of (epistemic) uncertainty of\nWalley, in which beliefs are represented through sets of probability\ndistributions, and we focus on the problem of modeling prior ignorance about a\ncategorical random variable. In this setting, it is a known result that a state\nof prior ignorance is not compatible with learning. To overcome this problem,\nanother state of beliefs, called \\emph{near-ignorance}, has been proposed.\nNear-ignorance resembles ignorance very closely, by satisfying some principles\nthat can arguably be regarded as necessary in a state of ignorance, and allows\nlearning to take place. What this paper does, is to provide new and substantial\nevidence that also near-ignorance cannot be really regarded as a way out of the\nproblem of starting statistical inference in conditions of very weak beliefs.\nThe key to this result is focusing on a setting characterized by a variable of\ninterest that is \\emph{latent}. We argue that such a setting is by far the most\ncommon case in practice, and we provide, for the case of categorical latent\nvariables (and general \\emph{manifest} variables) a condition that, if\nsatisfied, prevents learning to take place under prior near-ignorance. This\ncondition is shown to be easily satisfied even in the most common statistical\nproblems. We regard these results as a strong form of evidence against the\npossibility to adopt a condition of prior near-ignorance in real statistical\nproblems.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-04-29T03:16:20Z",
    "updated": "2009-04-29T03:16:20Z",
    "abstract_stats": {
      "total_words": 240,
      "unique_words": 118,
      "total_sentences": 9,
      "avg_words_per_sentence": 26.666666666666668,
      "avg_word_length": 5.0125
    }
  },
  {
    "arxiv_id": "0904.4608v2",
    "title": "Temporal data mining for root-cause analysis of machine faults in\n  automotive assembly lines",
    "authors": [
      "Srivatsan Laxman",
      "Basel Shadid",
      "P. S. Sastry",
      "K. P. Unnikrishnan"
    ],
    "abstract": "Engine assembly is a complex and heavily automated distributed-control\nprocess, with large amounts of faults data logged everyday. We describe an\napplication of temporal data mining for analyzing fault logs in an engine\nassembly plant. Frequent episode discovery framework is a model-free method\nthat can be used to deduce (temporal) correlations among events from the logs\nin an efficient manner. In addition to being theoretically elegant and\ncomputationally efficient, frequent episodes are also easy to interpret in the\nform actionable recommendations. Incorporation of domain-specific information\nis critical to successful application of the method for analyzing fault logs in\nthe manufacturing domain. We show how domain-specific knowledge can be\nincorporated using heuristic rules that act as pre-filters and post-filters to\nfrequent episode discovery. The system described here is currently being used\nin one of the engine assembly plants of General Motors and is planned for\nadaptation in other plants. To the best of our knowledge, this paper presents\nthe first real, large-scale application of temporal data mining in the\nmanufacturing domain. We believe that the ideas presented in this paper can\nhelp practitioners engineer tools for analysis in other similar or related\napplication domains as well.",
    "categories": [
      "cs.LG"
    ],
    "published": "2009-04-29T13:17:31Z",
    "updated": "2009-04-30T17:02:30Z",
    "abstract_stats": {
      "total_words": 202,
      "unique_words": 115,
      "total_sentences": 9,
      "avg_words_per_sentence": 22.444444444444443,
      "avg_word_length": 5.425742574257426
    }
  }
]